====================================================================================================
====================================================================================================

Episode: 1

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 1, State: 8, Action: up, Reward: -0.04, Next state: 8

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([-0.02, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓: 0.00  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 8, Action: up, Reward: -0.04, Next state: 4

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.03)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓: 0.00  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 4, Action: right, Reward: -0.04, Next state: 4

Q[4][right] = Q[4][right] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, -0.02]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓: 0.00  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 4, Action: down, Reward: -0.04, Next state: 8

Q[4][down] = Q[4][down] + 0.5 * (-0.04 + 0.8 * max([-0.03, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 9, Action: left, Reward: -0.04, Next state: 9

Q[9][left] = Q[9][left] + 0.5 * (-0.04 + 0.8 * max([0, 0, -0.02, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 9, Action: up, Reward: -0.04, Next state: 9

Q[9][up] = Q[9][up] + 0.5 * (-0.04 + 0.8 * max([-0.02, 0, -0.02, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 9, Action: up, Reward: -0.04, Next state: 9

Q[9][up] = Q[9][up] + 0.5 * (-0.04 + 0.8 * max([-0.03, 0, -0.02, 0]) - -0.03)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 9, Action: left, Reward: -0.04, Next state: 8

Q[9][left] = Q[9][left] + 0.5 * (-0.04 + 0.8 * max([-0.03, 0, 0, -0.02]) - -0.03)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ←:-0.03  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 8, Action: down, Reward: -0.04, Next state: 8

Q[8][down] = Q[8][down] + 0.5 * (-0.04 + 0.8 * max([-0.03, -0.02, 0, -0.02]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ←:-0.03  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.03, 0, -0.03, 0]) - -0.03)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 6, Action: left, Reward: -0.04, Next state: 6

Q[6][left] = Q[6][left] + 0.5 * (-0.04 + 0.8 * max([0, 0, -0.02, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([0, 0, 0, 0]) - 0.5)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 1, State: 3, Action: down, Reward: -1, Next state: 7

Q[3][down] = Q[3][down] + 0.5 * (-1 + 0.8 * max([0, 0, 0, 0]) - -0.5)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================
====================================================================================================

Episode: 2

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 2, State: 8, Action: down, Reward: -0.04, Next state: 8

Q[8][down] = Q[8][down] + 0.5 * (-0.04 + 0.8 * max([-0.03, -0.03, 0, -0.03]) - -0.03)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 8, Action: up, Reward: -0.04, Next state: 8

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.03, 0, -0.03]) - -0.035)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 8, Action: left, Reward: -0.04, Next state: 8

Q[8][left] = Q[8][left] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.03, -0.02, -0.03]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.02  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 8, Action: left, Reward: -0.04, Next state: 8

Q[8][left] = Q[8][left] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.03, -0.038000000000000006, -0.03]) - -0.038000000000000006)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.03  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.03, 0, -0.03, -0.02]) - -0.035)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.03  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 9, Action: left, Reward: -0.04, Next state: 8

Q[9][left] = Q[9][left] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.03, -0.038000000000000006, -0.035]) - -0.047)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.05  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.03, 0, -0.047, -0.02]) - -0.037500000000000006)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.05  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 9, Action: up, Reward: -0.04, Next state: 9

Q[9][up] = Q[9][up] + 0.5 * (-0.04 + 0.8 * max([-0.035, 0, -0.047, -0.02]) - -0.035)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.04  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.05  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 9, Action: up, Reward: -0.04, Next state: 9

Q[9][up] = Q[9][up] + 0.5 * (-0.04 + 0.8 * max([-0.037500000000000006, 0, -0.047, -0.02]) - -0.037500000000000006)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.04  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.05  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 9, Action: left, Reward: -0.04, Next state: 8

Q[9][left] = Q[9][left] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.03, -0.038000000000000006, -0.037500000000000006]) - -0.0555)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.03  | ↑:-0.04  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 8, Action: down, Reward: -0.04, Next state: 8

Q[8][down] = Q[8][down] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.047, -0.038000000000000006, -0.037500000000000006]) - -0.047)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.037500000000000006, 0, -0.0555, -0.02]) - -0.03875000000000001)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 9, Action: up, Reward: -0.04, Next state: 9

Q[9][up] = Q[9][up] + 0.5 * (-0.04 + 0.8 * max([-0.03875000000000001, 0, -0.0555, -0.02]) - -0.03875000000000001)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.02, 0, 0, 0]) - -0.03)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 10, Action: up, Reward: -0.04, Next state: 11

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.03)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([0, -0.02, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 11, Action: up, Reward: -1, Next state: 7

Q[11][up] = Q[11][up] + 0.5 * (-1 + 0.8 * max([0, 0, 0, 0]) - -0.5)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.00  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 2, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([0, -0.5, 0, 0]) - 0.5)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================
====================================================================================================

Episode: 3

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 3, State: 8, Action: up, Reward: -0.04, Next state: 4

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([0, -0.02, 0, -0.02]) - -0.037500000000000006)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑: 0.00  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: down, Reward: -0.04, Next state: 0

Q[0][down] = Q[0][down] + 0.5 * (-0.04 + 0.8 * max([0, -0.02, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0]) - -0.02)

Updated Q-values:

↑: 0.00  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →:-0.02  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 1, Action: left, Reward: -0.04, Next state: 0

Q[1][left] = Q[1][left] + 0.5 * (-0.04 + 0.8 * max([0, -0.02, 0, -0.02]) - -0.02)

Updated Q-values:

↑: 0.00  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←: 0.00  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: left, Reward: -0.04, Next state: 0

Q[0][left] = Q[0][left] + 0.5 * (-0.04 + 0.8 * max([0, -0.02, -0.02, -0.02]) - -0.02)

Updated Q-values:

↑: 0.00  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: up, Reward: -0.04, Next state: 0

Q[0][up] = Q[0][up] + 0.5 * (-0.04 + 0.8 * max([-0.02, -0.02, -0.02, -0.02]) - -0.02)

Updated Q-values:

↑:-0.02  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: up, Reward: -0.04, Next state: 0

Q[0][up] = Q[0][up] + 0.5 * (-0.04 + 0.8 * max([-0.038000000000000006, -0.02, -0.02, -0.02]) - -0.038000000000000006)

Updated Q-values:

↑:-0.04  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: down, Reward: -0.04, Next state: 4

Q[0][down] = Q[0][down] + 0.5 * (-0.04 + 0.8 * max([-0.02, -0.02, 0, -0.02]) - -0.03)

Updated Q-values:

↑:-0.04  ↓:-0.03  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.02  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: up, Reward: -0.04, Next state: 4

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.03, -0.02, 0, -0.02]) - -0.03)

Updated Q-values:

↑:-0.04  ↓:-0.03  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.03  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: up, Reward: -0.04, Next state: 4

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.02, 0, -0.02]) - -0.035)

Updated Q-values:

↑:-0.04  ↓:-0.03  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←: 0.00  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: left, Reward: -0.04, Next state: 4

Q[4][left] = Q[4][left] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.02, -0.02, -0.02]) - -0.02)

Updated Q-values:

↑:-0.04  ↓:-0.03  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.038000000000000006, -0.03, -0.02, -0.02]) - -0.0455)

Updated Q-values:

↑:-0.04  ↓:-0.03  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.02  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0, 0, -0.02, 0]) - -0.03)

Updated Q-values:

↑:-0.04  ↓:-0.03  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 1, Action: up, Reward: -0.04, Next state: 0

Q[1][up] = Q[1][up] + 0.5 * (-0.04 + 0.8 * max([-0.038000000000000006, -0.03, -0.02, -0.03]) - -0.028)

Updated Q-values:

↑:-0.04  ↓:-0.03  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: down, Reward: -0.04, Next state: 4

Q[0][down] = Q[0][down] + 0.5 * (-0.04 + 0.8 * max([-0.0455, -0.02, -0.02, -0.02]) - -0.043)

Updated Q-values:

↑:-0.04  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.02  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: down, Reward: -0.04, Next state: 8

Q[4][down] = Q[4][down] + 0.5 * (-0.04 + 0.8 * max([-0.037500000000000006, -0.047, -0.038000000000000006, -0.03875000000000001]) - -0.045)

Updated Q-values:

↑:-0.04  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.04  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 8, Action: up, Reward: -0.04, Next state: 4

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([-0.0455, -0.045, -0.02, -0.02]) - -0.04675)

Updated Q-values:

↑:-0.04  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.02  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: right, Reward: -0.04, Next state: 4

Q[4][right] = Q[4][right] + 0.5 * (-0.04 + 0.8 * max([-0.0455, -0.045, -0.02, -0.038000000000000006]) - -0.038000000000000006)

Updated Q-values:

↑:-0.04  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.038000000000000006, -0.043, -0.02, -0.03]) - -0.05075)

Updated Q-values:

↑:-0.04  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.02  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: left, Reward: -0.04, Next state: 0

Q[0][left] = Q[0][left] + 0.5 * (-0.04 + 0.8 * max([-0.038000000000000006, -0.043, -0.038000000000000006, -0.03]) - -0.038000000000000006)

Updated Q-values:

↑:-0.04  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: up, Reward: -0.04, Next state: 0

Q[0][up] = Q[0][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.043, -0.038000000000000006, -0.03]) - -0.051000000000000004)

Updated Q-values:

↑:-0.05  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: down, Reward: -0.04, Next state: 1

Q[0][down] = Q[0][down] + 0.5 * (-0.04 + 0.8 * max([-0.028, 0, -0.02, 0]) - -0.041499999999999995)

Updated Q-values:

↑:-0.05  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 1, Action: left, Reward: -0.04, Next state: 1

Q[1][left] = Q[1][left] + 0.5 * (-0.04 + 0.8 * max([-0.028, 0, -0.03, 0]) - -0.03)

Updated Q-values:

↑:-0.05  ↓:-0.04  | ↑:-0.03  ↓: 0.00  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.03  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 1, Action: down, Reward: -0.04, Next state: 1

Q[1][down] = Q[1][down] + 0.5 * (-0.04 + 0.8 * max([-0.028, -0.02, -0.03, 0]) - -0.02)

Updated Q-values:

↑:-0.05  ↓:-0.04  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.03  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 1, Action: left, Reward: -0.04, Next state: 0

Q[1][left] = Q[1][left] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.041499999999999995, -0.038000000000000006, -0.03]) - -0.047)

Updated Q-values:

↑:-0.05  ↓:-0.04  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.05  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: down, Reward: -0.04, Next state: 4

Q[0][down] = Q[0][down] + 0.5 * (-0.04 + 0.8 * max([-0.05075, -0.045, -0.02, -0.038000000000000006]) - -0.04875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.05  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.02  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: left, Reward: -0.04, Next state: 4

Q[4][left] = Q[4][left] + 0.5 * (-0.04 + 0.8 * max([-0.05075, -0.045, -0.038000000000000006, -0.038000000000000006]) - -0.038000000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.05  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.04  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: left, Reward: -0.04, Next state: 4

Q[4][left] = Q[4][left] + 0.5 * (-0.04 + 0.8 * max([-0.05075, -0.045, -0.054200000000000005, -0.038000000000000006]) - -0.054200000000000005)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.05  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.038000000000000006, -0.03]) - -0.057375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.04  →:-0.03  | ←:-0.05  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: left, Reward: -0.04, Next state: 0

Q[0][left] = Q[0][left] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, -0.03]) - -0.051000000000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.05  →:-0.03  | ←:-0.05  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([-0.028, -0.02, -0.047, 0]) - -0.035)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.05  →:-0.04  | ←:-0.05  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 1, Action: left, Reward: -0.04, Next state: 0

Q[1][left] = Q[1][left] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, -0.035]) - -0.0575)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.05  →:-0.04  | ←:-0.06  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([-0.028, -0.02, -0.0575, 0]) - -0.037500000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.05  →:-0.04  | ←:-0.06  →: 0.00  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0, 0, 0, 0.5]) - 0.18000000000000002)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.00  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.05  →:-0.04  | ←:-0.06  →: 0.18  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 2, Action: up, Reward: 1, Next state: 3

Q[2][up] = Q[2][up] + 0.5 * (1 + 0.8 * max([0, -0.5, 0, 0]) - 0.5)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.50  ↓: 0.00  | ↑: 0.00  ↓:-0.50  
←:-0.05  →:-0.04  | ←:-0.06  →: 0.18  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 3, State: 3, Action: down, Reward: -1, Next state: 7

Q[3][down] = Q[3][down] + 0.5 * (-1 + 0.8 * max([0.5, 0, 0, 0]) - -0.55)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.50  ↓: 0.00  | ↑: 0.00  ↓:-0.55  
←:-0.05  →:-0.04  | ←:-0.06  →: 0.18  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================
====================================================================================================

Episode: 4

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 4, State: 8, Action: up, Reward: -0.04, Next state: 4

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([-0.057375, -0.045, -0.054200000000000005, -0.038000000000000006]) - -0.058575)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.50  ↓: 0.00  | ↑: 0.00  ↓:-0.55  
←:-0.05  →:-0.04  | ←:-0.06  →: 0.18  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.04  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 4, State: 4, Action: right, Reward: -0.04, Next state: 0

Q[4][right] = Q[4][right] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, -0.037500000000000006]) - -0.054000000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.50  ↓: 0.00  | ↑: 0.00  ↓:-0.55  
←:-0.05  →:-0.04  | ←:-0.06  →: 0.18  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 4, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([-0.028, -0.02, -0.0575, 0.18000000000000002]) - 0.03325)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑:-0.03  ↓:-0.02  | ↑: 0.50  ↓: 0.00  | ↑: 0.00  ↓:-0.55  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.18  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 4, State: 1, Action: up, Reward: -0.04, Next state: 1

Q[1][up] = Q[1][up] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 0.18000000000000002]) - 0.038000000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.50  ↓: 0.00  | ↑: 0.00  ↓:-0.55  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.18  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 4, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.5, 0, 0, 0.5]) - 0.27)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.50  ↓: 0.00  | ↑: 0.00  ↓:-0.55  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 4, State: 2, Action: up, Reward: 1, Next state: 3

Q[2][up] = Q[2][up] + 0.5 * (1 + 0.8 * max([0, -0.55, 0, 0]) - 0.75)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.55  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 4, State: 3, Action: down, Reward: -1, Next state: 7

Q[3][down] = Q[3][down] + 0.5 * (-1 + 0.8 * max([0.5, 0, 0, 0]) - -0.575)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================
====================================================================================================

Episode: 5

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 5, State: 8, Action: up, Reward: -0.04, Next state: 4

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([-0.057375, -0.045, -0.054200000000000005, -0.054000000000000006]) - -0.0672875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.04  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 5, State: 4, Action: down, Reward: -0.04, Next state: 8

Q[4][down] = Q[4][down] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.047, -0.038000000000000006, -0.03875000000000001]) - -0.0577)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.04  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 5, State: 8, Action: left, Reward: -0.04, Next state: 8

Q[8][left] = Q[8][left] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.047, -0.054200000000000005, -0.03875000000000001]) - -0.054200000000000005)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.05  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 5, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.03875000000000001, 0, -0.0555, -0.03]) - -0.03937500000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.05  →:-0.04  | ←:-0.06  →:-0.03  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 5, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.03, 0, 0, 0]) - -0.035)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓: 0.00  | ↑:-0.50  ↓:-0.02  
←:-0.05  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 5, State: 10, Action: down, Reward: -0.04, Next state: 11

Q[10][down] = Q[10][down] + 0.5 * (-0.04 + 0.8 * max([-0.5, -0.02, 0, 0]) - -0.02)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓:-0.02  | ↑:-0.50  ↓:-0.02  
←:-0.05  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 5, State: 11, Action: up, Reward: -1, Next state: 7

Q[11][up] = Q[11][up] + 0.5 * (-1 + 0.8 * max([0.5, 0, 0, 0]) - -0.55)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.50  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.05  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 5, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([0, -0.575, 0, 0]) - 0.75)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.05  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================
====================================================================================================

Episode: 6

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 6, State: 8, Action: down, Reward: -0.04, Next state: 8

Q[8][down] = Q[8][down] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.059250000000000004, -0.054200000000000005, -0.03937500000000001]) - -0.059250000000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.05  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 8, Action: left, Reward: -0.04, Next state: 8

Q[8][left] = Q[8][left] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.059250000000000004, -0.06285, -0.03937500000000001]) - -0.06285)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.03875000000000001, 0, -0.0555, -0.035]) - -0.0396875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.04  ↓: 0.00  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 9, Action: down, Reward: -0.04, Next state: 9

Q[9][down] = Q[9][down] + 0.5 * (-0.04 + 0.8 * max([-0.03875000000000001, -0.02, -0.0555, -0.035]) - -0.02)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.04  ↓:-0.02  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 9, Action: up, Reward: -0.04, Next state: 9

Q[9][up] = Q[9][up] + 0.5 * (-0.04 + 0.8 * max([-0.047375, -0.02, -0.0555, -0.035]) - -0.047375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.02  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 9, Action: down, Reward: -0.04, Next state: 9

Q[9][down] = Q[9][down] + 0.5 * (-0.04 + 0.8 * max([-0.047375, -0.038000000000000006, -0.0555, -0.035]) - -0.038000000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.03, -0.02, 0, 0]) - -0.037500000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.03  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.02, 0, -0.02, 0]) - -0.035)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓: 0.00  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 6, Action: down, Reward: -0.04, Next state: 10

Q[6][down] = Q[6][down] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.02, 0, 0]) - -0.02)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →: 0.00  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 10, Action: right, Reward: -0.04, Next state: 6

Q[10][right] = Q[10][right] + 0.5 * (-0.04 + 0.8 * max([-0.02, -0.02, -0.02, 0]) - -0.02)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →: 0.00  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 6, Action: right, Reward: -1, Next state: 7

Q[6][right] = Q[6][right] + 0.5 * (-1 + 0.8 * max([0.75, 0, 0, 0]) - -0.19999999999999996)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.75  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 6, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([0, -0.575, 0, 0]) - 0.875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.04  | ←:-0.06  →:-0.04  | ←: 0.00  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================
====================================================================================================

Episode: 7

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 7, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.047375, -0.038000000000000006, -0.0555, -0.037500000000000006]) - -0.054843750000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.04  | ←: 0.00  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 7, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.02, 0, -0.02]) - -0.03875000000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.04  | ←: 0.00  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 7, State: 10, Action: left, Reward: -0.04, Next state: 9

Q[10][left] = Q[10][left] + 0.5 * (-0.04 + 0.8 * max([-0.047375, -0.038000000000000006, -0.0555, -0.03875000000000001]) - -0.0352)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.04  | ←:-0.04  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 7, State: 9, Action: down, Reward: -0.04, Next state: 9

Q[9][down] = Q[9][down] + 0.5 * (-0.04 + 0.8 * max([-0.047375, -0.054200000000000005, -0.0555, -0.03875000000000001]) - -0.054200000000000005)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.04  | ←:-0.04  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 7, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.02, -0.0352, -0.02]) - -0.047375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.02  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 7, State: 10, Action: down, Reward: -0.04, Next state: 10

Q[10][down] = Q[10][down] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.038000000000000006, -0.0352, -0.02]) - -0.038000000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.02  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 7, State: 10, Action: right, Reward: -0.04, Next state: 11

Q[10][right] = Q[10][right] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.02, 0, 0]) - -0.03)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.03  | ←: 0.00  →: 0.00  

====================================================================================================

Episode: 7, State: 11, Action: left, Reward: -0.04, Next state: 10

Q[11][left] = Q[11][left] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.038000000000000006, -0.0352, -0.03]) - -0.032)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.03  | ←:-0.03  →: 0.00  

====================================================================================================

Episode: 7, State: 10, Action: right, Reward: -0.04, Next state: 11

Q[10][right] = Q[10][right] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.02, -0.032, 0]) - -0.035)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.03  →: 0.00  

====================================================================================================

Episode: 7, State: 11, Action: right, Reward: -0.04, Next state: 11

Q[11][right] = Q[11][right] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.02, -0.032, -0.02]) - -0.02)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.02  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.03  →:-0.02  

====================================================================================================

Episode: 7, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.038000000000000006, -0.032, -0.02]) - -0.038000000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.03  →:-0.02  

====================================================================================================

Episode: 7, State: 11, Action: right, Reward: -0.04, Next state: 11

Q[11][right] = Q[11][right] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.038000000000000006, -0.032, -0.038000000000000006]) - -0.038000000000000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.03  →:-0.04  

====================================================================================================

Episode: 7, State: 11, Action: left, Reward: -1, Next state: 7

Q[11][left] = Q[11][left] + 0.5 * (-1 + 0.8 * max([0.875, 0, 0, 0]) - -0.16599999999999995)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓: 0.00  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 7, State: 7, Action: down, Reward: -0.04, Next state: 11

Q[7][down] = Q[7][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.038000000000000006, -0.16599999999999995, -0.038000000000000006]) - -0.0352)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.06  →:-0.05  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================
====================================================================================================

Episode: 8

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 8, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.047375, -0.054200000000000005, -0.0555, -0.047375]) - -0.066371875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.06  →:-0.07  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 9, Action: up, Reward: -0.04, Next state: 8

Q[9][up] = Q[9][up] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.059250000000000004, -0.06285, -0.066371875]) - -0.0673875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.06  | ↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.06  →:-0.07  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 8, Action: down, Reward: -0.04, Next state: 8

Q[8][down] = Q[8][down] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.073325, -0.06285, -0.066371875]) - -0.073325)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.06  →:-0.07  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 8, Action: left, Reward: -0.04, Next state: 8

Q[8][left] = Q[8][left] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.073325, -0.076565, -0.066371875]) - -0.076565)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.054200000000000005, -0.0555, -0.047375]) - -0.0721359375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.05  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.038000000000000006, -0.0352, -0.035]) - -0.0576875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.04  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 10, Action: right, Reward: -0.04, Next state: 10

Q[10][right] = Q[10][right] + 0.5 * (-0.04 + 0.8 * max([-0.035, -0.038000000000000006, -0.0352, -0.051500000000000004]) - -0.051500000000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.04  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.02, -0.02, -0.02, -0.19999999999999996]) - -0.0455)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑:-0.02  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.75, 0, 0, 0.5]) - 0.27)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.75  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 2, Action: up, Reward: -0.04, Next state: 2

Q[2][up] = Q[2][up] + 0.5 * (-0.04 + 0.8 * max([0.655, 0, 0, 0.5]) - 0.655)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.66  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.00  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 2, Action: left, Reward: -0.04, Next state: 1

Q[2][left] = Q[2][left] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 0.27]) - 0.08800000000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.66  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.27  | ←: 0.09  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.655, 0, 0.08800000000000001, 0.5]) - 0.377)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.66  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 2, Action: up, Reward: -0.04, Next state: 2

Q[2][up] = Q[2][up] + 0.5 * (-0.04 + 0.8 * max([0.5695, 0, 0.08800000000000001, 0.5]) - 0.5695)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.57  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 2, Action: up, Reward: -0.04, Next state: 2

Q[2][up] = Q[2][up] + 0.5 * (-0.04 + 0.8 * max([0.49255000000000004, 0, 0.08800000000000001, 0.5]) - 0.49255000000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.50  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 2, Action: right, Reward: -0.04, Next state: 6

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.27, -0.02, -0.02, -0.19999999999999996]) - 0.338)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.02  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 6, Action: down, Reward: -0.04, Next state: 10

Q[6][down] = Q[6][down] + 0.5 * (-0.04 + 0.8 * max([-0.0455, -0.038000000000000006, -0.0352, -0.051500000000000004]) - -0.044079999999999994)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.04  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.04  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 10, Action: left, Reward: -0.04, Next state: 9

Q[10][left] = Q[10][left] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.054200000000000005, -0.0555, -0.0576875]) - -0.05928000000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.04  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.05  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 9, Action: down, Reward: -0.04, Next state: 10

Q[9][down] = Q[9][down] + 0.5 * (-0.04 + 0.8 * max([-0.0455, -0.038000000000000006, -0.05928000000000001, -0.051500000000000004]) - -0.06230000000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.04  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.04  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 10, Action: down, Reward: -0.04, Next state: 10

Q[10][down] = Q[10][down] + 0.5 * (-0.04 + 0.8 * max([-0.0455, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - -0.054200000000000005)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.04  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑:-0.05  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.27, -0.044079999999999994, -0.02, -0.19999999999999996]) - 0.06525000000000002)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓:-0.04  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 6, Action: down, Reward: -0.04, Next state: 6

Q[6][down] = Q[6][down] + 0.5 * (-0.04 + 0.8 * max([0.27, 0.06596, -0.02, -0.19999999999999996]) - 0.06596)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.27  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.49255000000000004, 0, 0.08800000000000001, 0.338]) - 0.3120200000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.49  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 2, Action: up, Reward: -0.04, Next state: 2

Q[2][up] = Q[2][up] + 0.5 * (-0.04 + 0.8 * max([0.4232950000000001, 0, 0.08800000000000001, 0.338]) - 0.4232950000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.42  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 2, Action: up, Reward: 1, Next state: 3

Q[2][up] = Q[2][up] + 0.5 * (1 + 0.8 * max([0, -0.575, 0, 0]) - 0.7116475)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.00  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 8, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([0.5, -0.575, 0, 0]) - 0.5)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.08  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================
====================================================================================================

Episode: 9

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 9, State: 8, Action: left, Reward: -0.04, Next state: 8

Q[8][left] = Q[8][left] + 0.5 * (-0.04 + 0.8 * max([-0.0672875, -0.073325, -0.0851975, -0.0721359375]) - -0.0851975)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.07  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 8, Action: up, Reward: -0.04, Next state: 4

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([-0.057375, -0.0577, -0.054200000000000005, -0.054000000000000006]) - -0.07524375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 4, Action: right, Reward: -0.04, Next state: 0

Q[4][right] = Q[4][right] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 0.03325]) - -0.0337)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.03  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 0, Action: right, Reward: -0.04, Next state: 4

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([-0.057375, -0.0577, -0.054200000000000005, -0.0337]) - -0.016855000000000002)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →:-0.02  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 4, Action: up, Reward: -0.04, Next state: 4

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.0621675, -0.0577, -0.054200000000000005, -0.0337]) - -0.0621675)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →:-0.02  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 4, Action: up, Reward: -0.04, Next state: 4

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.06456375, -0.0577, -0.054200000000000005, -0.0337]) - -0.06456375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →:-0.02  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, -0.016855000000000002]) - -0.059023875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →:-0.02  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 0.377]) - 0.12237250000000002)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.38  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.7116475, 0, 0.08800000000000001, 0.338]) - 0.453159)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.00  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.45  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 2, Action: down, Reward: -0.04, Next state: 1

Q[2][down] = Q[2][down] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 0.453159]) - 0.1612636)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.16  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.45  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.7116475, 0.1612636, 0.08800000000000001, 0.338]) - 0.49123849999999997)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.71  ↓: 0.16  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.49  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 2, Action: up, Reward: -0.04, Next state: 2

Q[2][up] = Q[2][up] + 0.5 * (-0.04 + 0.8 * max([0.62048275, 0.1612636, 0.08800000000000001, 0.338]) - 0.62048275)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.62  ↓: 0.16  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.49  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 2, Action: up, Reward: -0.04, Next state: 2

Q[2][up] = Q[2][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.1612636, 0.08800000000000001, 0.338]) - 0.538434475)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.16  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.49  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 2, Action: down, Reward: -0.04, Next state: 1

Q[2][down] = Q[2][down] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 0.49123849999999997]) - 0.2571272)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.49  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 0.338]) - 0.44099304)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.34  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([0.5, -0.575, 0, 0]) - 0.869)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.50  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 9, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([0.95, -0.575, 0, 0]) - 0.95)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.08  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================
====================================================================================================

Episode: 10

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 10, State: 8, Action: up, Reward: -0.04, Next state: 8

Q[8][up] = Q[8][up] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, -0.073325, -0.0851975, -0.0721359375]) - -0.08647625)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.06230000000000001, -0.0555, -0.0576875]) - -0.07826796875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.06  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 9, Action: left, Reward: -0.04, Next state: 8

Q[9][left] = Q[9][left] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, -0.073325, -0.0851975, -0.07826796875]) - -0.07708)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.07  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 8, Action: down, Reward: -0.04, Next state: 8

Q[8][down] = Q[8][down] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, -0.0859925, -0.0851975, -0.07826796875]) - -0.0859925)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.059023875, -0.0577, -0.054200000000000005, -0.0337]) - -0.072613984375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.05  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 4, Action: left, Reward: -0.04, Next state: 4

Q[4][left] = Q[4][left] + 0.5 * (-0.04 + 0.8 * max([-0.059023875, -0.0577, -0.06058000000000001, -0.0337]) - -0.06058000000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.03  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 4, Action: right, Reward: -0.04, Next state: 4

Q[4][right] = Q[4][right] + 0.5 * (-0.04 + 0.8 * max([-0.059023875, -0.0577, -0.06058000000000001, -0.05033]) - -0.05033)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.05  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 4, Action: right, Reward: -0.04, Next state: 4

Q[4][right] = Q[4][right] + 0.5 * (-0.04 + 0.8 * max([-0.059023875, -0.0577, -0.06058000000000001, -0.065297]) - -0.065297)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.06  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 4, Action: down, Reward: -0.04, Next state: 8

Q[4][down] = Q[4][down] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, -0.0859925, -0.0851975, -0.072613984375]) - -0.07789559375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.06230000000000001, -0.07708, -0.0576875]) - -0.0793819921875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.06  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.06525000000000002, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - -0.022743749999999993)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.06230000000000001, -0.07708, -0.022743749999999993]) - 0.00352750000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.00  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 9, Action: down, Reward: -0.04, Next state: 9

Q[9][down] = Q[9][down] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, -0.022743749999999993]) - -0.0602475)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.00  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.00352750000000001, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - -0.029960874999999994)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.00  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.03  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.3120200000000001, 0.06596, -0.02, -0.19999999999999996]) - 0.10657175000000002)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.31  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.11  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.03  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 0.869]) - 0.48361000000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.87  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.48  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.11  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.03  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 2, Action: right, Reward: -0.04, Next state: 6

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.48361000000000004, 0.06596, -0.02, -0.19999999999999996]) - 0.607944)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.61  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.48  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.11  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.03  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 6, Action: up, Reward: -1, Next state: 7

Q[6][up] = Q[6][up] + 0.5 * (-1 + 0.8 * max([0.875, -0.0352, 0, 0]) - 0.09180500000000008)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.61  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.09  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.11  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.03  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 10, State: 7, Action: right, Reward: -1, Next state: 7

Q[7][right] = Q[7][right] + 0.5 * (-1 + 0.8 * max([0.875, -0.0352, 0, -0.14999999999999997]) - -0.14999999999999997)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.61  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.09  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.11  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.08  | ←:-0.08  →:-0.03  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================
====================================================================================================

Episode: 11

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 11, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, -0.029960874999999994]) - -0.07167534609375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.61  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.09  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.11  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →:-0.03  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 11, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.10657175000000002, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.007648262500000013)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.61  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.09  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.11  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 11, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.09180500000000008, 0.06596, -0.02, -0.19999999999999996]) - 0.07000787500000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.61  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.09  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 11, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 0.607944]) - 0.26908010000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 0.61  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.27  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 11, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([0.95, -0.575, 0, 0]) - 1.183972)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.18  | ←: 0.00  →: 0.00  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.27  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 11, State: 3, Action: right, Reward: 1, Next state: 3

Q[3][right] = Q[3][right] + 0.5 * (1 + 0.8 * max([0.95, -0.575, 0, 0.88]) - 0.88)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.18  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.27  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.07  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================
====================================================================================================

Episode: 12

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 12, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.007648262500000013]) - -0.052778368046874996)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.18  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.27  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.05  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 12, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.07000787500000004, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.011827281250000024)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.18  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.27  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.07  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.05  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 12, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.26908010000000004, 0.06596, -0.02, -0.19999999999999996]) - 0.12263597750000005)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.18  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.27  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.05  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 12, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 1.183972]) - 0.58812885)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.18  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.05  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 12, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 1.0455748]) - 1.0455748)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.05  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.05  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 12, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([0.95, -0.575, 0, 0.88]) - 1.4027874)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 0.95  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.05  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 12, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([1.355, -0.575, 0, 0.88]) - 1.355)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.05  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================
====================================================================================================

Episode: 13

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 13, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.011827281250000024]) - -0.041658271523437485)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 13, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, -0.009355446874999977]) - -0.009355446874999977)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.04  | ←:-0.08  →:-0.01  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 13, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.12263597750000005, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.02437666756250003)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.12  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 13, State: 10, Action: up, Reward: -0.04, Next state: 11

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.038000000000000006, -0.16599999999999995, -0.038000000000000006]) - 0.026117988750000015)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.04  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 13, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.054200000000000005, -0.16599999999999995, -0.038000000000000006]) - -0.054200000000000005)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.05  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.04  

====================================================================================================

Episode: 13, State: 11, Action: right, Reward: -0.04, Next state: 11

Q[11][right] = Q[11][right] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.054200000000000005, -0.16599999999999995, -0.054200000000000005]) - -0.054200000000000005)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.05  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.05  

====================================================================================================

Episode: 13, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.06878000000000001, -0.16599999999999995, -0.054200000000000005]) - -0.06878000000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.05  

====================================================================================================

Episode: 13, State: 11, Action: right, Reward: -1, Next state: 7

Q[11][right] = Q[11][right] + 0.5 * (-1 + 0.8 * max([0.875, -0.0352, 0, -0.14999999999999997]) - -0.17709999999999998)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 0.88  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 13, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([1.355, -0.575, 0, 0.88]) - 1.4795)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.04  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 14

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 14, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.02437666756250003]) - -0.03107846873671873)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.02  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 14, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.026117988750000015, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.002635529281250021)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.03  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.00  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 14, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.58812885, 0.06596, -0.02, -0.19999999999999996]) - 0.22831053437500007)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.59  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.23  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.00  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 14, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 1.4027874]) - 0.835179385)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.40  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.84  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.23  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.00  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 14, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([1.355, -0.575, 0, 0.88]) - 1.7433937)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.74  | ←: 0.00  →: 0.88  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.84  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.23  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.00  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 14, State: 3, Action: right, Reward: 1, Next state: 3

Q[3][right] = Q[3][right] + 0.5 * (1 + 0.8 * max([1.355, -0.575, 0, 1.4820000000000002]) - 1.4820000000000002)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.74  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.84  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.23  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.00  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 15

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 15, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.002635529281250021]) - -0.03448502265585936)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.74  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.84  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.23  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.00  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 15, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.22831053437500007, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.07264197839062504)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.74  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.84  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.23  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.07  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 15, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.835179385, 0.06596, -0.02, -0.19999999999999996]) - 0.4282270211875)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.74  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.84  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.43  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.07  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 15, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 1.7433937]) - 1.0949471725)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.74  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.09  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.43  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.07  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 15, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([1.355, -0.575, 0, 1.4820000000000002]) - 1.96449685)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.35  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.96  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.09  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.43  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.07  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 15, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([1.7703, -0.575, 0, 1.4820000000000002]) - 1.7703)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.77  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.96  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.09  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.43  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.03  | ←:-0.08  →: 0.07  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 16

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 16, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.07264197839062504]) - -0.008185719971679661)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.77  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.96  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.09  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.43  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.01  | ←:-0.08  →: 0.07  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 16, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.4282270211875, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.18761179767031255)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.77  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.96  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.09  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.43  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.01  | ←:-0.08  →: 0.19  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 16, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([1.0949471725, 0.06596, -0.02, -0.19999999999999996]) - 0.63209237959375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.77  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.96  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.09  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.63  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.01  | ←:-0.08  →: 0.19  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 16, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 1.96449685]) - 1.31327232625)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.77  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 1.96  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.63  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.01  | ←:-0.08  →: 0.19  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 16, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([1.7703, -0.575, 0, 1.4820000000000002]) - 2.190368425)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 1.77  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.63  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.01  | ←:-0.08  →: 0.19  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 16, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([2.09327, -0.575, 0, 1.4820000000000002]) - 2.09327)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.63  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →:-0.01  | ←:-0.08  →: 0.19  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 17

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 17, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.18761179767031255]) - 0.050951859082285195)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.63  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.05  | ←:-0.08  →: 0.19  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.1488506179032813]) - 0.1488506179032813)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.63  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.05  | ←:-0.08  →: 0.15  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.63209237959375, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.30726226078914065)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.63  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.05  | ←:-0.08  →: 0.31  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.07708, 0.30726226078914065]) - 0.41895109411253123)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.42  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.05  | ←:-0.08  →: 0.31  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 9, Action: left, Reward: -0.04, Next state: 8

Q[9][left] = Q[9][left] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, -0.0859925, -0.0851975, 0.050951859082285195]) - -0.03815925636708592)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.42  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.05  | ←:-0.04  →: 0.31  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.03815925636708592, 0.30726226078914065]) - 0.12838083385679885)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.42  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.13  | ←:-0.04  →: 0.31  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.41895109411253123, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.3012115680395828)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.42  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.13  | ←:-0.04  →: 0.30  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([1.31327232625, 0.06596, -0.02, -0.19999999999999996]) - 0.7147844775562655)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.31  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.71  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.13  | ←:-0.04  →: 0.30  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 6, Action: up, Reward: -1, Next state: 7

Q[6][up] = Q[6][up] + 0.5 * (-1 + 0.8 * max([1.4795, -0.0352, 0, -0.14999999999999997]) - 0.7484361631249999)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.75  ↓: 0.07  | ↑: 1.48  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.71  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.13  | ←:-0.04  →: 0.30  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 17, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([2.09327, -0.575, 0, 1.4820000000000002]) - 2.077058)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.75  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.71  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.13  | ←:-0.04  →: 0.30  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 18

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 18, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.03815925636708592, 0.3012115680395828]) - 0.16467504414423256)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.75  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.71  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.16  | ←:-0.04  →: 0.30  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 18, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.7147844775562655, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.4165195750422976)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.75  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.71  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.16  | ←:-0.04  →: 0.42  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 18, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.7484361631249999, 0.06596, -0.02, -0.19999999999999996]) - 0.6367667040281327)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.75  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.64  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.16  | ←:-0.04  →: 0.42  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 18, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 2.190368425]) - 1.2303654515625)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.19  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.23  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.64  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.16  | ←:-0.04  →: 0.42  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 18, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.09327, -0.575, 0, 1.4820000000000002]) - 2.4324922125)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.00  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.23  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.64  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.16  | ←:-0.04  →: 0.42  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 18, State: 3, Action: left, Reward: -0.04, Next state: 2

Q[3][left] = Q[3][left] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 2.4324922125]) - 0.9529968850000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.23  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.64  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.16  | ←:-0.04  →: 0.42  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 19

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 19, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, -0.0602475, -0.03815925636708592, 0.4165195750422976]) - 0.22894535208903533)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.23  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓:-0.06  | ↑: 0.64  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.23  | ←:-0.04  →: 0.42  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 19, State: 9, Action: down, Reward: -0.04, Next state: 9

Q[9][down] = Q[9][down] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, -0.03815925636708592, 0.4165195750422976]) - 0.11648408001691904)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.23  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.64  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.23  | ←:-0.04  →: 0.42  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 19, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.6367667040281327, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.4429664691324019)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.23  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.64  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.23  | ←:-0.04  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 19, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([1.2303654515625, 0.06596, -0.02, -0.19999999999999996]) - 0.7905295326390664)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 1.23  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.23  | ←:-0.04  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 19, State: 6, Action: up, Reward: -1, Next state: 7

Q[6][up] = Q[6][up] + 0.5 * (-1 + 0.8 * max([2.077058, -0.0352, 0, -0.14999999999999997]) - 0.9460059257812501)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.23  | ←:-0.04  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 19, State: 7, Action: up, Reward: -0.04, Next state: 6

Q[7][up] = Q[7][up] + 0.5 * (-0.04 + 0.8 * max([0.9460059257812501, 0.06596, -0.02, -0.19999999999999996]) - 1.3969313703125001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.23  | ←:-0.04  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 20

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 20, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, -0.03815925636708592, 0.4429664691324019]) - 0.27165926369747845)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.27  | ←:-0.04  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 20, State: 9, Action: left, Reward: -0.04, Next state: 8

Q[9][left] = Q[9][left] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, -0.0859925, -0.0851975, 0.27165926369747845]) - 0.06958407729544842)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.27  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 20, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.059023875, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.09222008184873923)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.06  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.09  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 20, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 0.12237250000000002]) - -0.0005629374999999853)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.09  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 20, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 0.44099304]) - 0.21758346600000006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 0.44  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.09  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 20, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 2.4324922125]) - 1.173493405)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.43  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.09  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 20, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.09327, -0.575, 0.9529968850000001, 1.4820000000000002]) - 2.55355410625)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.09  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.09  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 20, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([2.3839430000000004, -0.575, 0.9529968850000001, 1.4820000000000002]) - 2.3839430000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.09  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 21

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 21, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.4429664691324019]) - 0.20329662857733038)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.20  | ←: 0.07  →: 0.44  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 21, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.7905295326390664, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.5176950476218276)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.79  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.20  | ←: 0.07  →: 0.52  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 21, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.9460059257812501, 0.06596, -0.02, -0.19999999999999996]) - 0.7536671366320333)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.20  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.75  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.20  | ←: 0.07  →: 0.52  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 21, State: 6, Action: right, Reward: -1, Next state: 7

Q[6][right] = Q[6][right] + 0.5 * (-1 + 0.8 * max([1.3969313703125001, -0.0352, 0, -0.14999999999999997]) - -0.041227451874999876)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 1.40  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.75  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.20  | ←: 0.07  →: 0.52  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 21, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([2.3839430000000004, -0.575, 0.9529968850000001, 1.4820000000000002]) - 2.1520428851562503)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.75  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.20  | ←: 0.07  →: 0.52  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 22

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 22, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.5176950476218276]) - 0.2887263333373963)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.75  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.52  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.7536671366320333, -0.054200000000000005, -0.05928000000000001, -0.051500000000000004]) - 0.5403143784637272)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.75  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.05  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 10, Action: right, Reward: -0.04, Next state: 11

Q[10][right] = Q[10][right] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.06878000000000001, -0.16599999999999995, -0.17709999999999998]) - -0.07326200000000001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.75  ↓:-0.05  | ↑:-0.55  ↓:-0.07  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 11, Action: down, Reward: -0.04, Next state: 10

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([0.7536671366320333, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.24707685465281332)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.75  ↓:-0.05  | ↑:-0.55  ↓: 0.25  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 10, Action: up, Reward: -0.04, Next state: 11

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.24707685465281332, -0.16599999999999995, -0.17709999999999998]) - 0.455664310177142)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.46  ↓:-0.05  | ↑:-0.55  ↓: 0.25  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.202369169187532, -0.16599999999999995, -0.17709999999999998]) - 0.202369169187532)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.46  ↓:-0.05  | ↑:-0.55  ↓: 0.20  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.1621322522687788, -0.16599999999999995, -0.17709999999999998]) - 0.1621322522687788)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.46  ↓:-0.05  | ↑:-0.55  ↓: 0.16  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.12591902704190094, -0.16599999999999995, -0.17709999999999998]) - 0.12591902704190094)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.46  ↓:-0.05  | ↑:-0.55  ↓: 0.13  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.09332712433771086, -0.16599999999999995, -0.17709999999999998]) - 0.09332712433771086)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.46  ↓:-0.05  | ↑:-0.55  ↓: 0.09  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.06399441190393977, -0.16599999999999995, -0.17709999999999998]) - 0.06399441190393977)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.46  ↓:-0.05  | ↑:-0.55  ↓: 0.06  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 11, Action: down, Reward: -0.04, Next state: 10

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([0.455664310177142, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.19426293002282669)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.46  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([0.9460059257812501, 0.06596, -0.02, -0.041227451874999876]) - 0.586234525401071)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 0.95  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.59  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 2.55355410625]) - 1.4744246053906251)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.55  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.47  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.59  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.3839430000000004, -0.575, 0.9529968850000001, 1.4820000000000002]) - 2.7303542531250002)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.38  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.73  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.47  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.59  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 22, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([2.6455487000000004, -0.575, 0.9529968850000001, 1.4820000000000002]) - 2.6455487000000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.73  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.47  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.59  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.29  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 23

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 23, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.5403143784637272]) - 0.340488918054189)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.73  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.47  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.59  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.34  | ←: 0.07  →: 0.54  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 23, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.46628294061735454]) - 0.46628294061735454)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.73  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.47  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.59  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.34  | ←: 0.07  →: 0.47  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 23, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.586234525401071, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.4476352804691057)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.73  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.47  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.59  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.34  | ←: 0.07  →: 0.45  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 23, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([1.4744246053906251, 0.06596, -0.02, -0.041227451874999876]) - 0.8628871048567855)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.73  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.47  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.34  | ←: 0.07  →: 0.45  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 23, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 2.7303542531250002]) - 1.8093540039453127)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.73  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.81  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.34  | ←: 0.07  →: 0.45  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 23, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.6455487000000004, -0.575, 0.9529968850000001, 1.4820000000000002]) - 2.9233966065625)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.92  | ←: 0.95  →: 1.48  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.81  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.34  | ←: 0.07  →: 0.45  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 23, State: 3, Action: right, Reward: -1, Next state: 7

Q[3][right] = Q[3][right] + 0.5 * (-1 + 0.8 * max([2.1520428851562503, -0.0352, 0, -0.14999999999999997]) - 1.1018171540625001)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.92  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.81  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.34  | ←: 0.07  →: 0.45  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 24

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 24, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.4476352804691057]) - 0.3292985712147368)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.92  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.81  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.33  | ←: 0.07  →: 0.45  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 24, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([0.8628871048567855, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.548972482177267)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.92  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.81  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 0.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.33  | ←: 0.07  →: 0.55  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 24, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([1.8093540039453127, 0.06596, -0.02, -0.041227451874999876]) - 1.1351851540065179)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.92  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 1.81  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.33  | ←: 0.07  →: 0.55  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 24, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 2.9233966065625]) - 2.0540356445976564)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 2.92  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.33  | ←: 0.07  →: 0.55  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 24, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.6455487000000004, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.01991778328125)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.65  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.33  | ←: 0.07  →: 0.55  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 24, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([2.8809938300000004, -0.575, 0.9529968850000001, 1.1018171540625001]) - 2.8809938300000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.33  | ←: 0.07  →: 0.55  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 25

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 25, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.548972482177267]) - 0.3642382784782753)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.55  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.4740752339595403]) - 0.4740752339595403)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.47  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.4066677105635863]) - 0.4066677105635863)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.41  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.34600093950722766]) - 0.34600093950722766)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.1351851540065179, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.6070745313562209)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.14  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.61  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.0540356445976564, 0.06596, -0.02, -0.041227451874999876]) - 1.3692068348423216)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.05  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.37  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.61  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.01991778328125]) - 2.2149849356113283)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.37  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.61  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.8809938300000004, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.162356423640625)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.88  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.37  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.61  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 25, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.162356423640625]) - 2.6854394844562504)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓:-0.09  | ↑:-0.07  ↓: 0.12  | ↑: 1.37  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.61  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 26

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 26, State: 8, Action: down, Reward: -0.04, Next state: 8

Q[8][down] = Q[8][down] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 0.3642382784782753]) - 0.08269906139131014)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.37  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.36  | ←: 0.07  →: 0.61  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.6070745313562209]) - 0.40494895178162604)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.37  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.61  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.3692068348423216, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.8312199996150391)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.37  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.2149849356113283, 0.06596, -0.02, -0.041227451874999876]) - 1.550597391665692)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.07  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.55  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 6, Action: down, Reward: -0.04, Next state: 10

Q[6][down] = Q[6][down] + 0.5 * (-0.04 + 0.8 * max([1.550597391665692, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.6332189566662769)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.55  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.2149849356113283, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.6412926700773773)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.21  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.64  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.162356423640625]) - 2.3524350372619143)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.35  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.64  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.6854394844562504, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.155354005602813)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.69  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.35  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.64  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 26, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([2.9168955360106255, -0.575, 0.9529968850000001, 1.1018171540625001]) - 2.9168955360106255)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.92  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.35  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.64  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.40  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 27

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 27, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.8312199996150391]) - 0.5149624757368287)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.92  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.35  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.64  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.51  | ←: 0.07  →: 0.83  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 27, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.7280979996535353]) - 0.7280979996535353)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.92  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.35  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.64  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.51  | ←: 0.07  →: 0.73  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 27, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.6412926700773773, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.0005660678577186)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.92  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.35  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.64  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.51  | ←: 0.07  →: 1.00  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 27, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.3524350372619143, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.7416203499434544)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.92  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.35  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.74  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.51  | ←: 0.07  →: 1.00  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 27, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.155354005602813]) - 2.4183591208720823)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.92  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.16  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.74  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.51  | ←: 0.07  →: 1.00  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 27, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([2.9168955360106255, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.2444352172056568)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 2.92  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.74  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.51  | ←: 0.07  →: 1.00  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 27, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.125205982409563, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.125205982409563)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.74  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.51  | ←: 0.07  →: 1.00  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 28

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 28, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.0005660678577186]) - 0.6377076650115019)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.74  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.00  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.8805094610719468]) - 0.8805094610719468)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.74  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 0.88  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.7416203499434544, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.1169028705133552)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.74  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.12  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.1169028705133552]) - 1.2975713231770694)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.30  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.12  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.2975713231770694, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.0574799645275053)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.30  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.4183591208720823, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.5961293099373677)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.42  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.2444352172056568]) - 2.4869536473183036)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.125205982409563, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.3723000015666535)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.13  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 28, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.3126853841686064, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.3126853841686064)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.64  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 29

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 29, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0005629374999999853, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.29862865750575096)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑:-0.00  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 29, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 0.21758346600000006]) - 0.06675191765000003)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.22  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.07  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 29, State: 0, Action: right, Reward: -0.04, Next state: 4

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.06675191765000003, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.11549250006000004)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.07  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 29, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 0.11549250006000004]) - 0.05957295884900003)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.12  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.06  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 29, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 1.173493405]) - 0.50714361203)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.51  | ←:-0.06  →: 1.17  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.06  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 29, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.3723000015666535]) - 1.9156667031266617)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.51  | ←:-0.06  →: 1.92  | ←: 0.09  →: 3.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.06  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 29, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.3126853841686064, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.5112241544507694)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.31  ↓:-0.57  
←:-0.05  →: 0.51  | ←:-0.06  →: 1.92  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.06  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 29, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.481416845751746, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.481416845751746)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 0.51  | ←:-0.06  →: 1.92  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.06  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.30  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 30

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 30, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([0.05957295884900003, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.1531435122924755)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 0.51  | ←:-0.06  →: 1.92  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.06  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 30, State: 4, Action: up, Reward: -0.04, Next state: 4

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([0.033615662964100027, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.033615662964100027)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 0.51  | ←:-0.06  →: 1.92  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.03  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 30, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 0.50714361203]) - 0.19966527629405006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 0.51  | ←:-0.06  →: 1.92  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 30, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 1.9156667031266617]) - 0.9998384872656647)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 1.92  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 30, State: 1, Action: right, Reward: -0.04, Next state: 1

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 1.7041000328139955]) - 1.7041000328139955)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 1.70  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 30, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.5112241544507694]) - 2.2365396781873055)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 30, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.481416845751746, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.648178815526083)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.48  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 30, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.633275161176571, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.633275161176571)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.15  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 31

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 31, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.0574799645275053]) - 0.47956374195723983)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 1.06  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 31, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.9317319680747547]) - 0.9317319680747547)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 0.93  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 31, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 0.8185587712672793]) - 0.8185587712672793)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 0.82  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 31, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.5961293099373677, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.0277311096085868)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.60  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 1.03  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 31, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.4869536473183036, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.7728461138960054)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.49  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.77  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 1.03  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 31, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.648178815526083]) - 2.682748349869585)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.68  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.77  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 1.03  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 31, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.633275161176571, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.77739947223367)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.63  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.78  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.68  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.77  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 1.03  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 31, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.769947645058914, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.769947645058914)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.77  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.78  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.68  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.77  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.48  | ←: 0.07  →: 1.03  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 32

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 32, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.0277311096085868]) - 0.6308743148220546)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.77  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.78  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.68  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.77  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.63  | ←: 0.07  →: 1.03  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 32, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.7728461138960054, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.2030040003626956)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.77  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.78  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.68  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.77  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.63  | ←: 0.07  →: 1.20  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 32, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.682748349869585, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.9395223968958368)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.77  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.78  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.68  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.94  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.63  | ←: 0.07  →: 1.20  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 32, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.77739947223367]) - 2.8323339638282605)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.77  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.78  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.94  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.63  | ←: 0.07  →: 1.20  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 32, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.769947645058914, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.8966787941404006)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.77  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.94  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.63  | ←: 0.07  →: 1.20  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 32, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.8929528805530227, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.8929528805530227)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.94  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.63  | ←: 0.07  →: 1.20  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 33

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 33, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.2030040003626956]) - 0.7766387575561056)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.94  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.20  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 33, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.9395223968958368, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.3573109589396826)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.94  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.36  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 33, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.3573109589396826]) - 1.4926855820237914)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.49  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.36  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 33, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.4926855820237914, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.2557297122793578)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.49  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.26  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 33, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.8323339638282605, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.8592763765432)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.83  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.26  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 33, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.8966787941404006]) - 2.9548384995702905)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.26  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 33, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.8929528805530227, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.005520549291409)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.26  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 33, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.003657592497721, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.003657592497721)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.78  | ←: 0.07  →: 1.26  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 34

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 34, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.2557297122793578]) - 0.8706112636897959)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.26  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 34, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.8592763765432, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.351575406756959)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.86  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 34, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.351575406756959]) - 1.4502683509743837)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.45  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 34, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.4502683509743837, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.235895043768233)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.45  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.24  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 34, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.9548384995702905, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.8870695753153082)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.89  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.24  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 34, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.005520549291409]) - 3.0596274695017094)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.89  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.24  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 34, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.003657592497721, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.104223311644793)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.89  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.24  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 34, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.104223311644793]) - 3.6235181209067777)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.89  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.24  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 35

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 35, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.235895043768233]) - 0.9096636493521912)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.89  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.24  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.8870695753153082, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.35277535201024)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.89  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 10, Action: up, Reward: -0.04, Next state: 11

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.19426293002282669, -0.16599999999999995, -0.17709999999999998]) - 1.0012399596667847)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓: 0.19  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.154836637020544, -0.16599999999999995, -0.17709999999999998]) - 0.154836637020544)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓: 0.15  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.11935297331848961, -0.16599999999999995, -0.17709999999999998]) - 0.11935297331848961)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓: 0.12  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.08741767598664066, -0.16599999999999995, -0.17709999999999998]) - 0.08741767598664066)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓: 0.09  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.058675908387976594, -0.16599999999999995, -0.17709999999999998]) - 0.058675908387976594)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓: 0.06  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.032808317549178935, -0.16599999999999995, -0.17709999999999998]) - 0.032808317549178935)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓: 0.03  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, 0.009527485794261041, -0.16599999999999995, -0.17709999999999998]) - 0.009527485794261041)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓: 0.01  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.011425262785165063, -0.16599999999999995, -0.17709999999999998]) - -0.011425262785165063)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.01  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.030282736506648558, -0.16599999999999995, -0.17709999999999998]) - -0.030282736506648558)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.03  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.0472544628559837, -0.16599999999999995, -0.17709999999999998]) - -0.0472544628559837)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.05  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.06252901657038533, -0.16599999999999995, -0.17709999999999998]) - -0.06252901657038533)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.06  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.07627611491334679, -0.16599999999999995, -0.17709999999999998]) - -0.07627611491334679)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.08  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.08864850342201211, -0.16599999999999995, -0.17709999999999998]) - -0.08864850342201211)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.09  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.0997836530798109, -0.16599999999999995, -0.17709999999999998]) - -0.0997836530798109)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.10  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.1098052877718298, -0.16599999999999995, -0.17709999999999998]) - -0.1098052877718298)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.11  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.11882475899464683, -0.16599999999999995, -0.17709999999999998]) - -0.11882475899464683)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.12  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.12694228309518216, -0.16599999999999995, -0.17709999999999998]) - -0.12694228309518216)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.13  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.13424805478566393, -0.16599999999999995, -0.17709999999999998]) - -0.13424805478566393)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.13  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.14082324930709755, -0.16599999999999995, -0.17709999999999998]) - -0.14082324930709755)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.14  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.1467409243763878, -0.16599999999999995, -0.17709999999999998]) - -0.1467409243763878)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.15  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.15206683193874904, -0.16599999999999995, -0.17709999999999998]) - -0.15206683193874904)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.15  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.15686014874487414, -0.16599999999999995, -0.17709999999999998]) - -0.15686014874487414)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.16  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.16117413387038673, -0.16599999999999995, -0.17709999999999998]) - -0.16117413387038673)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.16  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.16505672048334807, -0.16599999999999995, -0.17709999999999998]) - -0.16505672048334807)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: down, Reward: -0.04, Next state: 11

Q[11][down] = Q[11][down] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.16855104843501328, -0.16599999999999995, -0.17709999999999998]) - -0.16855104843501328)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←:-0.17  →:-0.18  

====================================================================================================

Episode: 35, State: 11, Action: left, Reward: -0.04, Next state: 10

Q[11][left] = Q[11][left] + 0.5 * (-0.04 + 0.8 * max([1.0012399596667847, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.29749598386671394)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.00  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 35, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.0596274695017094, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.7044709676340761)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.06  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.70  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 35, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.104223311644793]) - 3.151503059408772)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.10  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.70  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 35, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.6235181209067777, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.001518904185108)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.62  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.70  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 35, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.7611663088161, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.7611663088161)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.70  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.91  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 36

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 36, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 0.7986972844169722]) - 0.7986972844169722)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.70  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.80  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 36, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.35277535201024]) - 0.9204587830125821)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.70  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.35  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 36, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.7044709676340761, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.3381760630587505)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.70  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.34  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 36, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.151503059408772, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.092836707580547)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.09  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.34  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 36, State: 6, Action: up, Reward: -1, Next state: 7

Q[6][up] = Q[6][up] + 0.5 * (-1 + 0.8 * max([2.1520428851562503, -0.0352, 0, -0.14999999999999997]) - 1.936568683766886)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 1.94  ↓: 0.63  | ↑: 2.15  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.09  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.34  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 36, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([3.7611663088161, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.080487966104565)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 1.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.09  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.34  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 37

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 37, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 0.8084129047113239]) - 0.8084129047113239)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 1.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.09  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.81  | ←: 0.07  →: 1.34  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 37, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.3381760630587505]) - 0.9194768775791622)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 1.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.09  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.34  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 37, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.092836707580547, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.486222714561594)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 1.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.09  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.49  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 37, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([1.936568683766886, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.801045827297028)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 1.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.80  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.49  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 37, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.001518904185108]) - 2.5488919035574864)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.00  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.55  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.80  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.49  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 37, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.7611663088161, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.005225975618994)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.76  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.55  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.80  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.49  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 37, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.88504967793449, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.88504967793449)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.55  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.80  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.49  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 38

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 38, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 0.807529189821246]) - 0.807529189821246)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.55  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.80  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.81  | ←: 0.07  →: 1.49  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 38, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.486222714561594]) - 0.9782536807352606)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.55  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.80  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.98  | ←: 0.07  →: 1.49  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 38, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.801045827297028, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.4435296881996083)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.55  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.80  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.98  | ←: 0.07  →: 1.44  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 38, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.5488919035574864, 0.6332189566662769, -0.02, -0.041227451874999876]) - 1.9000796750715085)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.55  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.90  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.98  | ←: 0.07  →: 1.44  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 38, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.005225975618994]) - 2.8565363420263408)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.01  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.86  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.90  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.98  | ←: 0.07  →: 1.44  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 38, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.88504967793449, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.056632858983293)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.89  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.06  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.86  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.90  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.98  | ←: 0.07  →: 1.44  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 38, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.996544710141041, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.996544710141041)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.06  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.86  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.90  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.98  | ←: 0.07  →: 1.44  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 39

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 39, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.4435296881996083]) - 1.0465387156474737)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.06  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.86  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.90  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.05  | ←: 0.07  →: 1.44  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 39, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.9000796750715085, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.4617967141284076)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.06  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.86  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.90  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.05  | ←: 0.07  →: 1.46  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 39, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.8565363420263408, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.0726543743462904)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.06  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.86  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.07  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.05  | ←: 0.07  →: 1.46  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 39, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.056632858983293]) - 3.0309213146064877)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.06  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.07  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.05  | ←: 0.07  →: 1.46  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 39, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.996544710141041, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.1269343135480625)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.00  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.13  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.07  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.05  | ←: 0.07  →: 1.46  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 39, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.096890239126937, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.096890239126937)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.10  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.13  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.07  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.05  | ←: 0.07  →: 1.46  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 40

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 40, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.4617967141284076]) - 1.0879880434751)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.10  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.13  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.07  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.09  | ←: 0.07  →: 1.46  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 40, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.0726543743462904, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.53996010680272)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.10  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.13  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.07  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.09  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 40, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.0309213146064877, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.2286957130157403)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.10  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.13  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.23  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.09  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 40, State: 6, Action: up, Reward: -0.04, Next state: 6

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([2.707829183145839, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.707829183145839)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.10  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.13  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.71  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.23  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.09  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 40, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.1269343135480625]) - 2.9846883169921448)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.10  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.13  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.98  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.23  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.09  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 40, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.096890239126937, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.202223252424806)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.10  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.98  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.23  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.09  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 40, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.187201215214244, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.187201215214244)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.19  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.98  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.23  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.09  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 41

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 41, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.53996010680272]) - 1.1399780644586381)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.19  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.98  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.23  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 41, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.2286957130157403, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.6414583386076562)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.19  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.98  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.23  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.64  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 41, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.9846883169921448, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.288223183304728)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.19  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 2.98  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.29  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.64  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 41, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.202223252424806]) - 3.153233459465995)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.19  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.29  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.64  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 41, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.187201215214244, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.275992112298101)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.19  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.29  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.64  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 41, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.26848109369282, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.26848109369282)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.27  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.29  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.64  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 42

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 42, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.6414583386076562]) - 1.2065723676723816)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.27  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.29  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.21  | ←: 0.07  →: 1.64  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 42, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.288223183304728, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7160184426257195)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.27  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.29  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.21  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 42, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.153233459465995, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.385404975438762)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.27  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.15  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.21  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 42, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.275992112298101]) - 3.267013574652238)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.27  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.21  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 42, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.26848109369282, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.345388493626178)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.27  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.21  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 42, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.341632984323538, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.341632984323538)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.21  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 43

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 43, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.0659151309051436]) - 1.0659151309051436)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.07  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 43, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([0.19966527629405006, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.5928236759701918)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.20  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.59  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 43, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 0.9998384872656647]) - 0.4797680330532909)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 1.00  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.59  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 43, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 2.2365396781873055]) - 1.3745351149077547)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.24  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.59  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 43, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.345388493626178]) - 2.836425236544124)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.59  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 43, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.341632984323538, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.409347440542504)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.59  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 43, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.409347440542504]) - 3.9145554683787704)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.91  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.59  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 44

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 44, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7160184426257195]) - 0.9628192150353838)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.91  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.96  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 44, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.385404975438762, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7921712114883646)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.91  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.39  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.96  | ←: 0.07  →: 1.79  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 44, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.267013574652238, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.4795079175802766)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.91  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.96  | ←: 0.07  →: 1.79  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 44, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.409347440542504]) - 3.3772457635431206)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.91  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.96  | ←: 0.07  →: 1.79  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 44, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.9145554683787704, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.27049590762276)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.91  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.96  | ←: 0.07  →: 1.79  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 44, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.023099921540894, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.023099921540894)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.96  | ←: 0.07  →: 1.79  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 45

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 45, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7921712114883646]) - 1.1782780921130378)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.79  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 45, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.4795079175802766, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.867888772776293)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.87  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 45, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.867888772776293]) - 1.9669094679006554)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.97  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.87  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 45, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.9669094679006554, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7007081735484086)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.97  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 45, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3772457635431206, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.314353039367576)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.31  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 45, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.27049590762276]) - 3.3768212448206647)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.27  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.31  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 45, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.023099921540894, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.244487922427737)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.02  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.31  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 45, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.120789929386804, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.120789929386804)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.12  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.31  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 46

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 46, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7007081735484086]) - 1.2494223154758823)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.12  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.31  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.25  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 46, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.314353039367576, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7560953025212347)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.12  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.31  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.25  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 46, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3768212448206647, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.4879050176120536)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.12  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.25  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 46, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.244487922427737]) - 3.3662057913814274)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.12  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.24  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.37  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.25  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 46, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.8000391301849636]) - 3.8000391301849636)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.12  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 3.80  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.37  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.25  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 46, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.120789929386804, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.048335536847204)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.12  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.05  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.37  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.25  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 46, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.208710936448124, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.208710936448124)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.21  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.05  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.37  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.25  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 47

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 47, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7560953025212347]) - 1.3071492787464352)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.21  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.05  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.37  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.31  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 47, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.4879050176120536, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8532096583054387)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.21  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.05  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.37  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.31  | ←: 0.07  →: 1.85  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 47, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3662057913814274, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.570434825358598)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.21  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.05  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.37  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.31  | ←: 0.07  →: 1.85  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 47, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.048335536847204]) - 3.282437110429595)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.21  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.05  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.28  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.31  | ←: 0.07  →: 1.85  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 47, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.208710936448124, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.207652143002852)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.21  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.21  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.28  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.31  | ←: 0.07  →: 1.85  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 47, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.2878398428033115, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.2878398428033115)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.29  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.21  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.28  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.31  | ←: 0.07  →: 1.85  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 48

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 48, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8532096583054387]) - 1.374858502695393)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.29  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.21  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.28  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.85  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 48, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.6478886924748948]) - 1.6478886924748948)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.29  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.21  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.28  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 48, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.570434825358598, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8321182763808865)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.29  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.21  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.28  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.83  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 48, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.282437110429595, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5781922568511373)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.29  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.21  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.28  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.83  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 48, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.207652143002852]) - 3.304279412415938)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.29  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.21  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.83  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 48, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.2878398428033115, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.3189620086227505)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.29  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.83  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 48, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.3189620086227505]) - 3.851504724850756)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.83  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 49

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 49, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8321182763808865]) - 1.4002765619000512)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.83  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.6289064487427978]) - 1.6289064487427978)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.446015803868518]) - 1.446015803868518)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.45  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.2814142234816663]) - 1.2814142234816663)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.28  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5781922568511373, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.651984014481288)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.304279412415938, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.590807893391944)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.3189620086227505]) - 3.3597245096570694)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.32  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.851504724850756, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.200082894251677)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.85  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 49, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([3.9663542523656803, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.9663542523656803)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.97  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 50

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 50, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([0.4797680330532909, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.872045494171342)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.97  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.48  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 50, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 1.3745351149077547]) - 0.7696980624897474)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.97  ↓:-0.57  
←:-0.05  →: 1.37  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 50, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 2.836425236544124]) - 1.801837652071527)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.97  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 2.84  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 50, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.200082894251677]) - 3.078245775972733)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.97  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.20  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 50, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.7600746048265097]) - 3.7600746048265097)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.97  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 50, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.9663542523656803, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.966579003359527)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.97  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 50, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.069718827129112, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.069718827129112)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.87  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 51

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 51, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.651984014481288]) - 1.0768163528781862)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.65  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.4667856130331591]) - 1.4667856130331591)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.47  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.3001070517298432]) - 1.3001070517298432)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.30  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.590807893391944, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.666376683221699)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3597245096570694, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.6192937505588)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.36  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.966579003359527]) - 3.2464938561723455)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.97  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.25  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 2, Action: right, Reward: -0.04, Next state: 6

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([3.2464938561723455, 0.6332189566662769, -0.02, -0.041227451874999876]) - 3.261887044148702)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.25  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.261887044148702]) - 2.9080017457456533)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.069718827129112, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.758831052925996)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.07  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 51, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.162746944416201, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.162746944416201)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.08  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 52

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 52, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.666376683221699]) - 1.1849588497277728)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.67  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 52, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.6192937505588, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8609058418343696)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 52, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8609058418343696]) - 2.0340092120131477)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.03  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 52, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.0340092120131477, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7240566057224438)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.03  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 52, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.9080017457456533, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.160205304304835)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.91  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.16  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 52, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.758831052925996]) - 2.937533294043225)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 3.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.16  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 52, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.162746944416201, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.044514304229478)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.04  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.16  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 52, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.24647224997458, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.24647224997458)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.25  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.04  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.16  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.18  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 53

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 53, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7240566057224438]) - 1.2621020671528638)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.25  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.04  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.16  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.26  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 53, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.160205304304835, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.706110424583156)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.25  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.04  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.16  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.26  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 53, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.937533294043225, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.2351159697697076)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.25  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.04  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.94  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.26  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 53, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.044514304229478]) - 3.0665723687134037)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.25  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.04  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.26  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 53, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.24647224997458, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.220846052104571)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.25  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.26  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 53, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.321825024977122, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.321825024977122)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.26  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 54

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 54, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.706110424583156]) - 1.2934952034096943)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.29  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 54, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.5154993821248404]) - 1.5154993821248404)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.29  | ←: 0.07  →: 1.52  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 54, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.2351159697697076, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.6317960789703032)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.29  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 54, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.0665723687134037, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.3241869323702153)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.32  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.29  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 54, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.220846052104571]) - 3.20162460519853)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.20  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.32  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.29  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 54, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.321825024977122, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.339153036043134)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.34  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.20  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.32  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.29  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 54, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.389642522479409, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.389642522479409)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.34  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.20  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.32  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.29  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 55

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 55, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.1441456830687249]) - 1.1441456830687249)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.34  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.20  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.32  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 55, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.6317960789703032]) - 1.204791273122484)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.34  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.20  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.32  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 55, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.3241869323702153, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7255728124332377)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.34  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.20  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.32  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 55, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.20162460519853, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.42274330826452)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.34  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.20  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.42  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 55, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.339153036043134]) - 3.3164735170165187)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.34  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.42  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 55, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.389642522479409, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.425433527013331)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.42  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 55, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.450678270231468, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.450678270231468)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.42  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 56

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 56, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7255728124332377]) - 1.2726247615345372)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.42  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 56, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.42274330826452, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8118837295224268)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.42  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.81  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 56, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3164735170165187, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5179610609388674)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.52  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.81  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 56, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.425433527013331]) - 3.4084101693135915)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.52  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.81  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 56, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.450678270231468, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.492988071599253)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.52  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.81  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 56, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.5056104432083215, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.5056104432083215)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.52  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.81  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 57

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 57, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8118837295224268]) - 1.3410658725762392)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.52  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.81  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5179610609388674, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8931262891367604)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.52  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.89  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8931262891367604]) - 1.996231046124138)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.00  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.89  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.6838136602230844]) - 1.6838136602230844)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.00  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.996231046124138, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.6203992485611973)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.00  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.62  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.4084101693135915, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.3414795907875057)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.41  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.34  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.62  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.492988071599253]) - 3.481400313296497)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.34  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.62  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.5056104432083215, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.548738213082955)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.51  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.34  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.62  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 57, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.555049398887489, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.555049398887489)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.34  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.62  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 58

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 58, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.1869592853186153]) - 1.1869592853186153)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.34  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.19  | ←: 0.07  →: 1.62  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 58, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.6203992485611973]) - 1.2216393420837866)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.34  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.62  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 58, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.3414795907875057, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.726791460595601)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.34  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 58, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.481400313296497, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.543299920712352)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 58, State: 6, Action: up, Reward: -1, Next state: 7

Q[6][up] = Q[6][up] + 0.5 * (-1 + 0.8 * max([3.080487966104565, -0.0352, 0, -0.14999999999999997]) - 2.472895343090075)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.08  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 58, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([4.555049398887489, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.8622637426072783)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 59

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 59, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([0.7696980624897474, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.8986988960377922)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.77  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.90  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 59, State: 4, Action: up, Reward: -0.04, Next state: 4

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([0.6727282562407726, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.6727282562407726)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.67  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.90  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 59, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 1.801837652071527]) - 1.037099188948997)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 1.80  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.04  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.90  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 59, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.078245775972733]) - 2.1122171364248565)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 2.11  | ←:-0.06  →: 3.08  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.04  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.90  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 59, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.548738213082955]) - 3.3386181732195483)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 2.11  | ←:-0.06  →: 3.34  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.04  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.90  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 59, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.555049398887489, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.596388866096474)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.56  ↓:-0.57  
←:-0.05  →: 2.11  | ←:-0.06  →: 3.34  | ←: 0.09  →: 4.60  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.04  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.90  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 59, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.59954445899874, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.59954445899874)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.11  | ←:-0.06  →: 3.34  | ←: 0.09  →: 4.60  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.04  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.90  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 60

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 60, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([1.037099188948997, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.844189123598495)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.11  | ←:-0.06  →: 3.34  | ←: 0.09  →: 4.60  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.04  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.84  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 60, State: 4, Action: up, Reward: -0.04, Next state: 4

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([0.9133892700540974, -0.07789559375, -0.06058000000000001, -0.065297]) - 0.9133892700540974)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.11  | ←:-0.06  →: 3.34  | ←: 0.09  →: 4.60  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 0.91  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.84  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 60, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.1122171364248565]) - 1.2815814895969913)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.11  | ←:-0.06  →: 3.34  | ←: 0.09  →: 4.60  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.84  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 60, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.3386181732195483]) - 2.3715558375002477)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.34  | ←: 0.09  →: 4.60  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.84  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 60, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.596388866096474]) - 3.487864633048364)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.60  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.84  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 60, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.59954445899874, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.638012216647733)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.84  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 60, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.639590013098866, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.639590013098866)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.84  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 61

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 61, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 0.7397702112386455]) - 0.7397702112386455)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.74  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.726791460595601]) - 1.0406016898575632)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.534112314536041]) - 1.534112314536041)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.53  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.3607010830824369]) - 1.3607010830824369)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.36  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.543299920712352, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.677670509826159)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.54  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.472895343090075, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.240808097592206)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 2.47  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.638012216647733]) - 3.0716525582041307)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.64  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.639590013098866, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.674842113563413)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.67  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 61, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.67563101178898, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.67563101178898)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.68  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.67  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 62

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 62, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 0.9165415208718068]) - 0.9165415208718068)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.68  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.67  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.92  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 62, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.677670509826159]) - 1.109338964366367)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.68  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.67  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.11  | ←: 0.07  →: 1.68  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 62, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.240808097592206, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.715158493949962)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.68  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.67  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.24  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.11  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 62, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.0716525582041307, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.3290650720777553)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.68  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.67  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.11  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 62, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.674842113563413]) - 3.385763124527431)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.68  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.67  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.39  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.11  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 62, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.67563101178898, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.707673461497299)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.68  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.71  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.39  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.11  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 62, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.707673461497299]) - 4.200884890493409)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.20  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.71  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.39  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.11  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 63

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 63, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.715158493949962]) - 1.2207328797631682)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.20  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.71  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.39  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 63, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.3290650720777553, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7692052758060832)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.20  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.71  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.39  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 63, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.385763124527431, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.49883778584985)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.20  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.71  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.39  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 63, State: 6, Action: up, Reward: -0.04, Next state: 6

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([3.027186812074688, 0.6332189566662769, -0.02, -0.041227451874999876]) - 3.027186812074688)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.20  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.71  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 63, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.707673461497299]) - 3.3766627906362636)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.20  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.71  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 63, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.200884890493409, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.534190686946014)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.20  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.53  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 63, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.280796401444068, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.280796401444068)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.28  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.53  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.22  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 64

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 64, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([1.2815814895969913, -0.07789559375, -0.06058000000000001, -0.065297]) - 1.1029990357203805)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.28  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.53  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.28  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.10  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 64, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.3715558375002477]) - 1.5694130797985948)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.28  ↓:-0.57  
←:-0.05  →: 2.37  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.53  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.57  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.10  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 64, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.487864633048364]) - 2.5609237719694695)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.28  ↓:-0.57  
←:-0.05  →: 2.56  | ←:-0.06  →: 3.49  | ←: 0.09  →: 4.53  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.57  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.10  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 64, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.534190686946014]) - 3.5376085913025874)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.28  ↓:-0.57  
←:-0.05  →: 2.56  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.53  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.57  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.10  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 64, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.280796401444068, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.479413904050634)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.28  ↓:-0.57  
←:-0.05  →: 2.56  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.57  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.10  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 64, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.352716761299661, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.352716761299661)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.35  ↓:-0.57  
←:-0.05  →: 2.56  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.57  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.10  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 65

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 65, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([1.5694130797985948, -0.07789559375, -0.06058000000000001, -0.065297]) - 1.1592647497796282)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.35  ↓:-0.57  
←:-0.05  →: 2.56  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.57  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.16  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 65, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.5609237719694695]) - 1.7890760486870851)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.35  ↓:-0.57  
←:-0.05  →: 2.56  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.16  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 65, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.5376085913025874]) - 2.67550532250577)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.35  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.16  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 65, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.479413904050634]) - 3.5405698572715476)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.35  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.16  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 65, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.352716761299661, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.480793656545181)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.35  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.16  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 65, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.417445085169694, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.417445085169694)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.42  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.16  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 66

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 66, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7692052758060832]) - 1.2673144852122475)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.42  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 66, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.49883778584985, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8641377522429816)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.42  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.50  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 66, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3766627906362636, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.580084009179431)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.42  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 66, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.480793656545181]) - 3.4606488579362042)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.42  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.48  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.46  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 66, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.417445085169694, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.507374862340468)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.42  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.46  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 66, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.507374862340468]) - 3.9916724875210345)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.99  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.46  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 67

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 67, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8641377522429816]) - 1.3593123435033165)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.99  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.46  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.86  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 67, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.580084009179431, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9441024797932631)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.99  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.46  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.94  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 67, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.4606488579362042, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.654301547764197)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.99  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.46  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.65  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.94  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 67, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.507374862340468]) - 3.5132743739042893)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.99  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.51  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.65  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.94  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 67, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.9916724875210345, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.350356426178648)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.99  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.65  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.94  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 67, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.092505238768931, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.092505238768931)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.65  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.94  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 68

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 68, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9441024797932631]) - 1.4372971636689635)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.65  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.94  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.654301547764197, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 2.0137718590023104)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.65  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 2.01  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 2.0137718590023104]) - 2.1126595174830225)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.11  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 2.01  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7923946731020792]) - 1.7923946731020792)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.11  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.79  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.1126595174830225, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7212611435442486)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.11  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.5132743739042893, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.441639508303227)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.51  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.350356426178648]) - 3.4767797574236035)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.895320783560783]) - 3.895320783560783)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.90  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.4857887052047047]) - 3.4857887052047047)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.49  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.092505238768931, -0.575, 0.9529968850000001, 1.1018171540625001]) - 3.8798964481099247)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.09  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.88  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 68, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.183254714892038, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.183254714892038)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.18  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.88  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.44  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 69

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 69, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7212611435442486]) - 1.3871530392521811)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.18  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.88  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 69, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.441639508303227, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8172863750934152)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.18  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.88  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 69, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.4767797574236035, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.591531657121055)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.18  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.88  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.48  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 69, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.8798964481099247]) - 3.270348457955772)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.18  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 3.88  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 69, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.183254714892038, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.113250110011777)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.18  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.11  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 69, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.264929243402834, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.264929243402834)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.26  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.11  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 70

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 70, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8172863750934152]) - 1.4004910696634567)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.26  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.11  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 70, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.591531657121055, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9252558503951296)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.26  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.11  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.93  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 70, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.270348457955772, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5839052117428363)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.26  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.11  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.27  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.93  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 70, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.113250110011777]) - 3.260474272982597)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.26  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.11  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.26  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.93  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 70, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.264929243402834, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.262596752367022)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.26  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.26  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.93  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 70, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.338436319062551, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.338436319062551)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.26  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.93  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 71

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 71, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.240441962697111]) - 1.240441962697111)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.26  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.24  | ←: 0.07  →: 1.93  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 71, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9252558503951296]) - 1.3703233215066075)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.26  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.93  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 71, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5839052117428363, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9761900098946992)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.26  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 71, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.260474272982597, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.576142315064457)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.26  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 71, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.262596752367022]) - 3.3152758374381075)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 71, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.338436319062551, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.3666729038085315)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.34  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 71, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.4045926871562955, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.4045926871562955)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.40  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.37  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 72

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 72, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9761900098946992]) - 1.4556376647111835)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.40  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.46  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 72, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.576142315064457, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9985519309731326)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.40  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.46  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 72, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3152758374381075, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5941814925074715)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.40  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.32  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.46  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 72, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.3666729038085315]) - 3.3843070802424666)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.40  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.37  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.46  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 72, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.4045926871562955, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.445173526766784)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.40  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.45  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.46  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 72, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.445173526766784]) - 3.960365754284861)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.96  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.45  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.46  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 73

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 73, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([1.7890760486870851, -0.07789559375, -0.06058000000000001, -0.065297]) - 1.4234492518304258)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.96  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.45  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.79  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.42  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 73, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.67550532250577]) - 1.9447401533458506)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.96  ↓:-0.57  
←:-0.05  →: 2.68  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.45  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.42  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 73, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.5405698572715476]) - 2.733980604161504)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.96  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.54  | ←: 0.09  →: 4.45  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.42  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 73, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.445173526766784]) - 3.528354339342487)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.96  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.45  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.42  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 73, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([3.960365754284861, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.306733065097337)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 3.96  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.31  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.42  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 73, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.064329178856375, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.064329178856375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.06  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.31  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.42  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 74

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 74, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9985519309731326]) - 1.4911453983044658)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.06  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.31  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 2.00  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 74, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5941814925074715, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 2.016948562489555)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.06  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.31  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 2.02  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 74, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.3843070802424666, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.6308135783507227)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.06  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.31  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.38  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.63  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 2.02  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 74, State: 6, Action: up, Reward: -0.04, Next state: 6

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([3.02587637221822, 0.6332189566662769, -0.02, -0.041227451874999876]) - 3.02587637221822)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.06  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.31  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.03  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.63  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 2.02  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 74, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.306733065097337]) - 3.2156314121480447)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.06  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.31  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.22  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.63  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 2.02  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 74, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.064329178856375, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.279098204091218)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.06  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.22  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.63  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 2.02  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 74, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.1578962609707375, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.1578962609707375)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.22  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.63  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 2.02  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 75

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 75, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 2.016948562489555]) - 1.5323521241480549)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.22  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.63  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.53  | ←: 0.07  →: 2.02  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 75, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.6308135783507227, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 2.0407997125850668)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.22  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.63  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.53  | ←: 0.07  →: 2.04  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 75, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.2156314121480447, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5816593540345796)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.22  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.53  | ←: 0.07  →: 2.04  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 75, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.279098204091218]) - 3.2994549877105097)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.28  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.53  | ←: 0.07  →: 2.04  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 75, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.1578962609707375, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.302707606433904)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.16  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.53  | ←: 0.07  →: 2.04  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 75, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.242106634873664, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.242106634873664)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.53  | ←: 0.07  →: 2.04  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 76

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 76, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.3591169117332496]) - 1.3591169117332496)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 2.04  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 2.0407997125850668]) - 1.4758783409006515)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 2.04  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8167197413265601]) - 1.8167197413265601)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5816593540345796, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9210236122771118)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.58  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.2994549877105097, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5906116721014936)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.30  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 6, Action: up, Reward: -0.04, Next state: 6

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([2.9495094889394586, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.9495094889394586)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.95  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 6, Action: up, Reward: -0.04, Next state: 6

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([2.6345585400455125, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.6345585400455125)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.63  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.302707606433904]) - 3.018362312596318)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.30  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.02  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.242106634873664, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.348196457166417)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.24  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.02  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 76, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.317895971386298, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.317895971386298)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.02  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 77

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 77, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9210236122771118]) - 1.4863486153611705)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.02  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 77, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5906116721014936, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9767564749791533)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.02  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.59  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 77, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.018362312596318, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.482650761089274)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.02  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 77, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.348196457166417]) - 3.228459739164726)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.35  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 77, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.317895971386298, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.401256617137728)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.40  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 77, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.386106374247668, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.386106374247668)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.40  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.49  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 78

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 78, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.3177137538250534]) - 1.3177137538250534)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.40  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.32  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9767564749791533]) - 1.429559466904188)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.40  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.98  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.482650761089274, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9614385419252862)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.40  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.48  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.228459739164726, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5127092762105274)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.40  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.401256617137728]) - 3.354732516437454)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.40  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.35  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 2, Action: right, Reward: -0.04, Next state: 6

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([3.354732516437454, 0.6332189566662769, -0.02, -0.041227451874999876]) - 3.5225213151438455)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 3.52  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.35  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.5225213151438455]) - 3.066374784276265)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 3.52  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.386106374247668, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.01570320727099)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 78, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.447495736822901, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.447495736822901)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 79

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 79, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.2666035202137693]) - 1.2666035202137693)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.27  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 79, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9614385419252862]) - 1.397877176876999)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 79, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5127092762105274, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.965802981446854)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.51  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.97  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 79, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.965802981446854]) - 2.0226758306840056)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.02  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.97  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 79, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.0226758306840056, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7719718229970294)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.02  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 79, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.066374784276265, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.2178878290525086)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.07  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.22  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 79, State: 6, Action: up, Reward: -1, Next state: 7

Q[6][up] = Q[6][up] + 0.5 * (-1 + 0.8 * max([3.8622637426072783, -0.0352, 0, -0.14999999999999997]) - 2.578092889181044)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.58  ↓: 0.63  | ↑: 3.86  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.22  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 79, State: 7, Action: up, Reward: 1, Next state: 3

Q[7][up] = Q[7][up] + 0.5 * (1 + 0.8 * max([4.447495736822901, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.210130166032799)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.58  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.22  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 80

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 80, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7719718229970294]) - 1.3877273176373113)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.58  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.22  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 80, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.2178878290525086, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.753141043119518)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.58  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.22  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 80, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.578092889181044, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.1201810701986723)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.58  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.12  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 80, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.01570320727099]) - 2.8753277274989184)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.02  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.88  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.12  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 80, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.447495736822901, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.286849898364656)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.88  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.12  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 80, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.502746163140611, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.502746163140611)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.88  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.12  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.39  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 81

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 81, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.753141043119518]) - 1.3751200760664628)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.88  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.12  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 81, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.1201810701986723, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.704642949639228)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.88  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.12  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 81, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.8753277274989184, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.1902216260989036)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 2.88  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.19  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 81, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.286849898364656]) - 3.1324038230953217)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.13  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.19  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 81, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.8381649085281904]) - 3.8381649085281904)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 3.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.13  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.19  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 81, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.502746163140611, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.22018091952034)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.13  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.19  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 81, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.552471546826551, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.552471546826551)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.55  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.13  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.19  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 82

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 82, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.704642949639228]) - 1.3494172178889225)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.55  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.13  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.19  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 1.70  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 82, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.1902216260989036, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7084101252591755)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.55  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.13  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.19  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 82, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.1324038230953217, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.3280723422875806)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.55  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.13  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 82, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.22018091952034]) - 3.234274279355797)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.55  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.22  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 82, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.552471546826551, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.43107907849079)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.55  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 82, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.597224392143896, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.597224392143896)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 83

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 83, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([1.9447401533458506, -0.07789559375, -0.06058000000000001, -0.065297]) - 1.4326046702828017)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.94  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 83, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.733980604161504]) - 2.045962318337527)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 2.05  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 83, State: 0, Action: right, Reward: -0.04, Next state: 4

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([2.045962318337527, -0.07789559375, -0.06058000000000001, -0.065297]) - 2.165375229415763)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.17  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 2.05  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 83, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.165375229415763]) - 1.8691312509350686)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.17  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 83, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.528354339342487]) - 2.4740293504448765)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.53  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 83, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.43107907849079]) - 3.5166088010675596)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.43  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 83, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.597224392143896, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.5544292961029536)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.60  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 83, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.637501952929506, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.637501952929506)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 84

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 84, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7084101252591755]) - 1.379666385245071)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.71  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 84, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.3280723422875806, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.76543399954462)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.33  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 84, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.234274279355797, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.437745882886109)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.23  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 84, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.5544292961029536]) - 3.41890885811908)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.55  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.42  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 84, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.637501952929506, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.63221542922328)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.64  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.63  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.42  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 84, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.6737517576365555, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.6737517576365555)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.67  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.63  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.42  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 85

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 85, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.76543399954462]) - 1.3760067924403834)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.67  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.63  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.42  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.77  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 85, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.568890599590158]) - 1.568890599590158)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.67  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.63  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.42  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.57  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 85, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.437745882886109, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7395436529495227)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.67  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.63  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.42  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.74  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 85, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.41890885811908, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.5664364846906866)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.67  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.63  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.42  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.74  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 85, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.63221542922328]) - 3.542340600748852)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.67  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.63  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.74  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 85, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.6737517576365555, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.685608417666262)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.67  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.74  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 85, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.7063765818729, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.7063765818729)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.38  | ←: 0.07  →: 1.74  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 86

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 86, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7395436529495227]) - 1.3638208574000008)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.74  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.5455892876545705]) - 1.5455892876545705)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.55  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.5664364846906866, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.77936923770356)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.57  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.78  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.77936923770356]) - 1.9749659374267674)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.97  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.78  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.9749659374267674, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.659670993822487)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.97  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.66  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.542340600748852, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.3844192090129246)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.54  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.38  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.66  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.685608417666262]) - 3.625413667440931)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.69  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.63  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.38  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.66  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.7063765818729, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.725354841582291)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.71  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.63  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.38  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.66  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 86, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.735738923685609, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.735738923685609)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.74  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.63  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.38  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.36  | ←: 0.07  →: 1.66  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 87

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 87, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.659670993822487]) - 1.3257788262289951)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.74  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.63  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.38  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.33  | ←: 0.07  →: 1.66  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 87, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.3844192090129246, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7636031805164132)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.74  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.63  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.38  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.33  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 87, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.625413667440931, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.6223750714828347)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.74  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.63  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.33  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 87, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.725354841582291]) - 3.682848770353382)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.74  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.33  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 87, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.735738923685609, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.756972990265389)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.74  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.33  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 87, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.762165031317048, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.762165031317048)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.33  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 88

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 88, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.1732009436060955]) - 1.1732009436060955)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.17  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.035880849245486]) - 1.035880849245486)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.04  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7636031805164132]) - 1.2033816968293083)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.76  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.5672428624647718]) - 1.5672428624647718)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.57  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.3905185762182946]) - 1.3905185762182946)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.39  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.6223750714828347, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7242093167022812)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.62  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7242093167022812]) - 1.9808712624223297)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.98  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.72  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.531788385032053]) - 1.531788385032053)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.98  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.53  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.9808712624223297, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.5382426974849586)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.98  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.682848770353382, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.4435751393525176)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.756972990265389]) - 3.7242135812828465)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.2612756912388505]) - 4.2612756912388505)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.26  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.762165031317048, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.535503858146244)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.76  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 88, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.785948528185344, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.785948528185344)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.20  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 89

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 89, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.0630435271463774]) - 1.0630435271463774)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 0.9367391744317397]) - 0.9367391744317397)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 0.94  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.5382426974849586]) - 1.0636666662098533)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.54  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.3644184277364628]) - 1.3644184277364628)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.36  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.2079765849628166]) - 1.2079765849628166)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.21  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.4435751393525176, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.5614183482224153)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.44  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.56  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.7242135812828465, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.6914730021893973)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.72  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.69  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.56  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.535503858146244]) - 3.656308333899921)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.66  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.69  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.56  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.785948528185344, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.68213134034726)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.79  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.66  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.69  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.56  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 89, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.80735367536681, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.80735367536681)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.81  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.66  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.69  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.06  | ←: 0.07  →: 1.56  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 90

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 90, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.5614183482224153]) - 1.1364006723938926)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.81  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.66  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.69  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.56  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 90, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.6914730021893973, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8372983749869665)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.81  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.66  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.69  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.84  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 90, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.656308333899921, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.788259834654667)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.81  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.66  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.84  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 90, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.68213134034726]) - 3.6810067030888645)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.81  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.84  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 90, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.80735367536681, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.764007140320354)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.81  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.84  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 90, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.826618307830129, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.826618307830129)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.14  | ←: 0.07  →: 1.84  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 91

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 91, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8372983749869665]) - 1.2831196861917329)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.84  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 91, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.6335685374882698]) - 1.6335685374882698)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.63  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 91, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.4502116837394428]) - 1.4502116837394428)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.45  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 91, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.788259834654667, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.8204097757315882)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.79  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 91, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.6810067030888645, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.8465325985628795)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.68  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.85  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 91, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.764007140320354]) - 3.726106207672574)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.76  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.73  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.85  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 91, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.826618307830129, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.812650893292229)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.83  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.81  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.73  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.85  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 91, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.843956477047117, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.843956477047117)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.84  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.81  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.73  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.85  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.28  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 92

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 92, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.8204097757315882]) - 1.3497237533885018)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.84  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.81  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.73  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.85  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 1.82  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 92, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.8465325985628795, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 2.028817927290946)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.84  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.81  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.73  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.85  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 2.03  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 92, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.726106207672574, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.8937087823504695)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.84  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.81  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.73  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.89  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 2.03  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 92, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.812650893292229]) - 3.768113461153179)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.84  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.81  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.89  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 2.03  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 92, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.843956477047117, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.843908037464962)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.84  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.89  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 2.03  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 92, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.8595608293424055, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.8595608293424055)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.89  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.35  | ←: 0.07  →: 2.03  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 93

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 93, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 2.028817927290946]) - 1.4663890476106292)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.89  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.03  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 93, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.8937087823504695, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 2.151892476585661)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.89  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 93, State: 10, Action: up, Reward: -0.04, Next state: 11

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.55, -0.16855104843501328, 0.29749598386671394, -0.17709999999999998]) - 1.5458527847219203)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.55  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.30  →:-0.18  

====================================================================================================

Episode: 93, State: 11, Action: left, Reward: -0.04, Next state: 10

Q[11][left] = Q[11][left] + 0.5 * (-0.04 + 0.8 * max([1.5458527847219203, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 0.7470891058221252)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.55  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 93, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.768113461153179, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.260171776822232)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.77  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 93, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.843908037464962]) - 3.801619945562574)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.84  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.80  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 93, State: 2, Action: right, Reward: -0.04, Next state: 6

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([3.801619945562574, 0.6332189566662769, -0.02, -0.041227451874999876]) - 3.9226019969575106)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 3.92  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.80  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 93, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.9226019969575106]) - 3.449850771564291)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 3.92  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.45  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 93, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.8595608293424055, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.405125330215718)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.86  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.45  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 93, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.873604746408166, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.873604746408166)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.87  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.45  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.47  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 94

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 94, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 2.151892476585661]) - 1.573951514439579)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.87  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.45  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.57  | ←: 0.07  →: 2.15  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 94, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.260171776822232, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9600149490217231)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.87  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.45  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.26  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.57  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 94, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.449850771564291, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.4900261970368325)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.87  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.45  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.57  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 94, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.405125330215718]) - 3.4669755178684327)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.87  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.41  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.57  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 94, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.873604746408166, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.652004563671126)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.87  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.57  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 94, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.8862442717673495, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.8862442717673495)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.57  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 95

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 95, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.396556362995621]) - 1.396556362995621)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.40  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 95, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([1.8691312509350686, -0.07789559375, -0.06058000000000001, -0.065297]) - 1.425930681871838)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.87  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 95, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.4740293504448765]) - 1.9041773656454848)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.47  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 95, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.5166088010675596]) - 2.6236581956494622)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.52  | ←: 0.09  →: 4.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 95, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.652004563671126]) - 3.59910622600223)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.65  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 95, State: 2, Action: right, Reward: -0.04, Next state: 2

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.166804107304014]) - 4.166804107304014)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.17  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 95, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.8862442717673495, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.537899762358947)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.89  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 95, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.897619844590615, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.897619844590615)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.43  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 96

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 96, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9600149490217231]) - 1.4769713205446084)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.96  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 96, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.7440134541195509]) - 1.7440134541195509)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.74  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 96, State: 9, Action: right, Reward: -0.04, Next state: 9

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.5496121087075958]) - 1.5496121087075958)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.55  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 96, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.4900261970368325, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.750816533168531)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.49  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 96, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.4669755178684327, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.6118033056657897)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 3.47  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 96, State: 6, Action: up, Reward: -1, Next state: 7

Q[6][up] = Q[6][up] + 0.5 * (-1 + 0.8 * max([4.210130166032799, -0.0352, 0, -0.14999999999999997]) - 2.917539825347336)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 4.21  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 96, State: 7, Action: up, Reward: -1, Next state: 7

Q[7][up] = Q[7][up] + 0.5 * (-1 + 0.8 * max([3.2891171494295195, -0.0352, 0, -0.14999999999999997]) - 3.2891171494295195)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 97

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 97, State: 8, Action: right, Reward: -0.04, Next state: 4

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([1.9041773656454848, -0.07789559375, -0.06058000000000001, -0.065297]) - 1.4801566065304983)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.90  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 97, State: 4, Action: up, Reward: -0.04, Next state: 0

Q[4][up] = Q[4][up] + 0.5 * (-0.04 + 0.8 * max([-0.051000000000000004, -0.04875, -0.051000000000000004, 2.6236581956494622]) - 1.9815519610825274)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.62  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 97, State: 0, Action: right, Reward: -0.04, Next state: 1

Q[0][right] = Q[0][right] + 0.5 * (-0.04 + 0.8 * max([0.038000000000000006, -0.02, -0.0575, 3.59910622600223]) - 2.7314715882256233)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.60  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 97, State: 1, Action: right, Reward: -0.04, Next state: 2

Q[1][right] = Q[1][right] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.537899762358947]) - 3.5947130179446942)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.54  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 97, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.897619844590615, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.7279978190157195)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.90  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 97, State: 3, Action: up, Reward: -0.04, Next state: 2

Q[3][up] = Q[3][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.7279978190157195]) - 4.3200090499015955)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.48  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 98

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 98, State: 8, Action: right, Reward: -0.04, Next state: 8

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.08647625, 0.08269906139131014, -0.0851975, 1.3121409458774485]) - 1.3121409458774485)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.31  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.750816533168531]) - 1.3363970862061367)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.75  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.6118033056657897, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9001295888505814)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.61  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.917539825347336, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.4529175829718293)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.92  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.7279978190157195]) - 3.3299690402799555)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.73  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.33  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 2, Action: right, Reward: -0.04, Next state: 6

Q[2][right] = Q[2][right] + 0.5 * (-0.04 + 0.8 * max([3.3299690402799555, 0.6332189566662769, -0.02, -0.041227451874999876]) - 3.675986525619842)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 3.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.33  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 3.675986525619842]) - 3.1153791303879146)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 3.68  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.12  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.3200090499015955, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.065996882770559)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.32  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.07  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.12  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 98, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.388008144911437, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.388008144911437)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.07  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.12  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.34  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 99

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 99, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9001295888505814]) - 1.408250378643301)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.07  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.12  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.41  | ←: 0.07  →: 1.90  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 99, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.4529175829718293, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9112318276140225)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.07  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.12  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.41  | ←: 0.07  →: 1.91  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 99, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([3.1153791303879146, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.4526104436410803)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.07  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.12  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.41  | ←: 0.07  →: 1.91  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 99, State: 6, Action: up, Reward: -0.04, Next state: 6

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([2.7838412173491234, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.7838412173491234)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.07  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 2.78  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.41  | ←: 0.07  →: 1.91  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 99, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.065996882770559]) - 2.9983193617827855)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.07  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.41  | ←: 0.07  →: 1.91  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 99, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.388008144911437, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.288201699349854)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.39  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.41  | ←: 0.07  →: 1.91  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 99, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.449207330420293, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.449207330420293)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.41  | ←: 0.07  →: 1.91  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================
====================================================================================================

Episode: 100

====================================================================================================
====================================================================================================

====================================================================================================

Episode: 100, State: 8, Action: right, Reward: -0.04, Next state: 9

Q[8][right] = Q[8][right] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9112318276140225]) - 1.4486179203672596)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.91  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 100, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([2.4526104436410803, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.9166600912634433)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.45  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 100, State: 10, Action: up, Reward: -0.04, Next state: 9

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([-0.0673875, 0.11648408001691904, 0.06958407729544842, 1.9166600912634433]) - 1.9729692583259175)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.97  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.92  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 100, State: 9, Action: right, Reward: -0.04, Next state: 10

Q[9][right] = Q[9][right] + 0.5 * (-0.04 + 0.8 * max([1.9729692583259175, -0.054200000000000005, -0.05928000000000001, -0.07326200000000001]) - 1.7275177489620885)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 1.97  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 100, State: 10, Action: up, Reward: -0.04, Next state: 6

Q[10][up] = Q[10][up] + 0.5 * (-0.04 + 0.8 * max([2.9983193617827855, 0.6332189566662769, -0.02, -0.041227451874999876]) - 2.165812373876073)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.00  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.17  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 100, State: 6, Action: up, Reward: -0.04, Next state: 2

Q[6][up] = Q[6][up] + 0.5 * (-0.04 + 0.8 * max([0.538434475, 0.2571272, 0.08800000000000001, 4.288201699349854]) - 3.1944403606313347)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.29  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.19  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.17  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 100, State: 2, Action: right, Reward: 1, Next state: 3

Q[2][right] = Q[2][right] + 0.5 * (1 + 0.8 * max([4.449207330420293, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.423783781843044)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.45  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.42  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.19  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.17  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Episode: 100, State: 3, Action: up, Reward: 1, Next state: 3

Q[3][up] = Q[3][up] + 0.5 * (1 + 0.8 * max([4.504286597378264, -0.575, 0.9529968850000001, 1.1018171540625001]) - 4.504286597378264)

Updated Q-values:

↑:-0.05  ↓:-0.05  | ↑: 0.04  ↓:-0.02  | ↑: 0.54  ↓: 0.26  | ↑: 4.50  ↓:-0.57  
←:-0.05  →: 2.73  | ←:-0.06  →: 3.59  | ←: 0.09  →: 4.42  | ←: 0.95  →: 1.10  
----------------------------------------------------------------------------
↑: 1.98  ↓:-0.08  | ################# | ↑: 3.19  ↓: 0.63  | ↑: 3.29  ↓:-0.04  
←:-0.06  →:-0.07  | ################# | ←:-0.02  →:-0.04  | ←: 0.00  →:-0.15  
----------------------------------------------------------------------------
↑:-0.09  ↓: 0.08  | ↑:-0.07  ↓: 0.12  | ↑: 2.17  ↓:-0.05  | ↑:-0.55  ↓:-0.17  
←:-0.09  →: 1.45  | ←: 0.07  →: 1.73  | ←:-0.06  →:-0.07  | ←: 0.75  →:-0.18  

====================================================================================================

Optimal policy

→ → → ↑ 
↑ # ↑ ↑ 
→ → ↑ ← 
